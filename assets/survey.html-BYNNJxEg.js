import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{o as t,c as n,f as i}from"./app-BAJq8wgY.js";const a={},o=i('<p>https://github.com/PJLab-ADG/awesome-knowledge-driven-AD</p><p>CVPR2024 论文接收列表 https://cvpr.thecvf.com/Conferences/2024/AcceptedPapers</p><p>LocLLM: Exploiting Generalizable Human Keypoint Localization via Large Language Model https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_LocLLM_Exploiting_Generalizable_Human_Keypoint_Localization_via_Large_Language_Model_CVPR_2024_paper.pdf</p><p>https://github.com/kennethwdk/LocLLM</p><p>PointLLM: Empowering Large Language Models to Understand Point Clouds https://github.com/OpenRobotLab/PointLLM?tab=readme-ov-file</p><p>HandDiffuse: Generative Controllers for Two-Hand Interactions via Diffusion Models (CVPR&#39;24) https://handdiffuse.github.io/</p><p>GPT4Point : A Unified Framework for Point-Language Understanding and Generation https://github.com/Pointcept/GPT4Point</p><p>Visual In-Context Prompting https://openaccess.thecvf.com/content/CVPR2024/papers/Li_Visual_In-Context_Prompting_CVPR_2024_paper.pdf</p><p>Visual Instruction Tuning https://llava-vl.github.io</p><p>Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs https://arxiv.org/pdf/2401.06209 https://github.com/tsb0601/MMVP</p><h2 id="describing-differences-in-image-sets-with-natural-language" tabindex="-1"><a class="header-anchor" href="#describing-differences-in-image-sets-with-natural-language"><span>Describing Differences in Image Sets with Natural Language</span></a></h2><p>https://understanding-visual-datasets.github.io/VisDiff-website/ https://github.com/Understanding-Visual-Datasets/VisDiff https://openaccess.thecvf.com/content/CVPR2024/papers/Dunlap_Describing_Differences_in_Image_Sets_with_Natural_Language_CVPR_2024_paper.pdf blog: https://voxel51.com/blog/cvpr-2024-survival-guide-five-vision-language-papers-you-dont-want-to-miss/</p><p>Low-Resource Vision Challenges for Foundation Models https://xiaobai1217.github.io/Low-Resource-Vision/</p>',13),s=[o];function p(r,c){return t(),n("div",null,s)}const u=e(a,[["render",p],["__file","survey.html.vue"]]),d=JSON.parse(`{"path":"/discover/uncover/survey.html","title":"","lang":"en-US","frontmatter":{"description":"https://github.com/PJLab-ADG/awesome-knowledge-driven-AD CVPR2024 论文接收列表 https://cvpr.thecvf.com/Conferences/2024/AcceptedPapers LocLLM: Exploiting Generalizable Human Keypoint ...","head":[["meta",{"property":"og:url","content":"https://2-mo.github.io/discover/uncover/survey.html"}],["meta",{"property":"og:site_name","content":"Tiu Mo's Blog"}],["meta",{"property":"og:description","content":"https://github.com/PJLab-ADG/awesome-knowledge-driven-AD CVPR2024 论文接收列表 https://cvpr.thecvf.com/Conferences/2024/AcceptedPapers LocLLM: Exploiting Generalizable Human Keypoint ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2024-09-01T07:46:43.000Z"}],["meta",{"property":"article:author","content":"Tiu Mo"}],["meta",{"property":"article:modified_time","content":"2024-09-01T07:46:43.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2024-09-01T07:46:43.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Tiu Mo\\",\\"url\\":\\"https://2-mo.github.io\\"}]}"]]},"headers":[{"level":2,"title":"Describing Differences in Image Sets with Natural Language","slug":"describing-differences-in-image-sets-with-natural-language","link":"#describing-differences-in-image-sets-with-natural-language","children":[]}],"git":{"createdTime":1720278353000,"updatedTime":1725176803000,"contributors":[{"name":"2-mo","email":"1982800736@qq.com","commits":1}]},"readingTime":{"minutes":0.47,"words":142},"filePathRelative":"discover/uncover/survey.md","localizedDate":"July 6, 2024","excerpt":"<p>https://github.com/PJLab-ADG/awesome-knowledge-driven-AD</p>\\n<p>CVPR2024 论文接收列表 https://cvpr.thecvf.com/Conferences/2024/AcceptedPapers</p>\\n<p>LocLLM: Exploiting Generalizable Human Keypoint Localization\\nvia Large Language Model\\nhttps://openaccess.thecvf.com/content/CVPR2024/papers/Wang_LocLLM_Exploiting_Generalizable_Human_Keypoint_Localization_via_Large_Language_Model_CVPR_2024_paper.pdf</p>","autoDesc":true}`);export{u as comp,d as data};
