import{_ as d}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as s,o as c,c as h,a as e,b as n,d as o,w as l,e as a,f as r}from"./app-BTgncBQC.js";const p={},u=e("h1",{id:"readme🧐",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#readme🧐"},[e("span",null,"ReadMe🧐")])],-1),g=e("h2",{id:"介绍",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#介绍"},[e("span",null,"介绍")])],-1),b=e("br",null,null,-1),m=e("br",null,null,-1),f={href:"http://10.16.104.13:1805/happy-learning/tohappylearning",target:"_blank",rel:"noopener noreferrer"},_=e("h2",{id:"小组老大",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#小组老大"},[e("span",null,"小组老大")])],-1),C={href:"https://faculty.cqupt.edu.cn/lengjiaxu/zh_CN/index.htm",target:"_blank",rel:"noopener noreferrer"},w=e("h2",{id:"使用指南",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#使用指南"},[e("span",null,"使用指南")])],-1),v={href:"http://10.16.104.13:1805/root/users-guide",target:"_blank",rel:"noopener noreferrer"},y=r('<p>此 <code>README</code> 文档仅作为索引, 主要内容为入门基础知识和各研究方向简介，详细笔记请见 <code>1.科研方向</code> 文件夹。</p><hr><h2 id="文档总览" tabindex="-1"><a class="header-anchor" href="#文档总览"><span>文档总览</span></a></h2><p>[toc]</p><hr><h2 id="新生入门" tabindex="-1"><a class="header-anchor" href="#新生入门"><span>新生入门</span></a></h2>',6),A=e("li",null,"首先学习 Andrew Ng 的 Machine Learning 在线课程，要做课后作业(MATLAB)；",-1),V=e("li",null,"其次学习 Andrew Ng 的 Deep Learning 在线课程，要做课后作业（Python+tensorflow），这个过程可能需要花3-5天学习python的基础语法；",-1),E=e("li",null,"学习CS231n在线课程，并完成大作业。",-1),P=e("li",null,"https://mofanpy.com/",-1),R=e("h2",{id:"科研基础",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#科研基础"},[e("span",null,"科研基础")])],-1),k=e("code",null,"《高等数学》",-1),x=e("code",null,"《线性代数》",-1),D=e("code",null,"《概率论与数理统计》",-1),S=e("code",null,"《矩阵论》",-1),I=e("code",null,"《凸优化》",-1),T=e("br",null,null,-1),M={href:"https://www.bilibili.com/video/BV1ys411472E",target:"_blank",rel:"noopener noreferrer"},N={href:"https://www.bilibili.com/video/BV1ys411472E",target:"_blank",rel:"noopener noreferrer"},B={href:"https://www.bilibili.com/video/BV1zx411g7gq",target:"_blank",rel:"noopener noreferrer"},F={href:"https://www.bilibili.com/video/BV164411b7dx",target:"_blank",rel:"noopener noreferrer"},L={href:"https://www.bilibili.com/video/BV1nJ411z7fe",target:"_blank",rel:"noopener noreferrer"},W=e("br",null,null,-1),q={href:"https://www.runoob.com/linux/linux-tutorial.html",target:"_blank",rel:"noopener noreferrer"},j=e("br",null,null,-1),K={href:"https://www.runoob.com/python3/python3-tutorial.html",target:"_blank",rel:"noopener noreferrer"},H=e("br",null,null,-1),X={href:"https://pillow-cn.readthedocs.io/zh_CN/latest/",target:"_blank",rel:"noopener noreferrer"},z=e("br",null,null,-1),G={href:"https://www.runoob.com/numpy/numpy-tutorial.html",target:"_blank",rel:"noopener noreferrer"},O=e("br",null,null,-1),J={href:"https://pytorch.apachecn.org/docs/1.4/",target:"_blank",rel:"noopener noreferrer"},Y=e("h2",{id:"科研工具",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#科研工具"},[e("span",null,"科研工具")])],-1),U={href:"https://geckoiplc.org/register?aff=nxkYWh33",target:"_blank",rel:"noopener noreferrer"},Z={href:"https://scholar.google.com/",target:"_blank",rel:"noopener noreferrer"},Q=e("br",null,null,-1),$={href:"https://ieeexplore.ieee.org/Xplore/home.jsp",target:"_blank",rel:"noopener noreferrer"},ee=e("br",null,null,-1),ne={href:"https://www.sciencedirect.com/",target:"_blank",rel:"noopener noreferrer"},oe=e("br",null,null,-1),te={href:"https://link.springer.com/",target:"_blank",rel:"noopener noreferrer"},re=e("br",null,null,-1),ae={href:"https://arxiv.org/",target:"_blank",rel:"noopener noreferrer"},ie=e("br",null,null,-1),se={href:"https://www.sci-hub.ren/",target:"_blank",rel:"noopener noreferrer"},le={href:"https://www.mendeley.com/",target:"_blank",rel:"noopener noreferrer"},de={href:"https://www.endnote.com/",target:"_blank",rel:"noopener noreferrer"},ce={href:"https://www.zotero.org/",target:"_blank",rel:"noopener noreferrer"},he={href:"http://tug.org/texlive/",target:"_blank",rel:"noopener noreferrer"},pe={href:"https://www.overleaf.com/login",target:"_blank",rel:"noopener noreferrer"},ue=e("li",null,"论文作图：PPT、Visio(Windows)、OmniGraffle(Mac)； 直接保存成PDF就是矢量图，使用Adobe Acrobat将图片多余部分裁剪。",-1),ge={href:"https://code.visualstudio.com/",target:"_blank",rel:"noopener noreferrer"},be=r('<h2 id="科研方向" tabindex="-1"><a class="header-anchor" href="#科研方向"><span>科研方向</span></a></h2><h3 id="✧-行人检测-person-detection-高峰-博士" tabindex="-1"><a class="header-anchor" href="#✧-行人检测-person-detection-高峰-博士"><span>✧ 行人检测（Person Detection）-&gt; <code>高峰 (博士)</code></span></a></h3><h4 id="论文汇总-论文汇总链接-例如github上的-awesome-系列" tabindex="-1"><a class="header-anchor" href="#论文汇总-论文汇总链接-例如github上的-awesome-系列"><span>论文汇总：论文汇总链接，例如GitHub上的 <code>Awesome</code> 系列</span></a></h4><h5 id="➢-推荐综述" tabindex="-1"><a class="header-anchor" href="#➢-推荐综述"><span>➢ 推荐综述</span></a></h5><p>[1] From Handcrafted to Deep Features for Pedestrian Detection: A Survey (TPAMI2021) 涵盖了2020年及以前从传统到深度学习的行人检测所有知识。但是，2020Detr横空出世,2021突飞猛进，2022基于Detr思想的第一篇行人检测顶会问世,个人觉得这是里程碑式的作品。因为自Faster-RCNN问世以来，行人检测领域百分之80以上的文章都是Faster-RCNN的变种。未来可能Detr替代Faster-RCNN，成为行人检测领域的Baseline。目前DETR相关资料非常少，这部分知识需要自己想办法。</p><h5 id="➢-优秀团队-学术大佬" tabindex="-1"><a class="header-anchor" href="#➢-优秀团队-学术大佬"><span>➢ 优秀团队 / 学术大佬</span></a></h5><p>■ 【旷视团队】<br> [1] Detection in Crowded Scenes: One Proposal, Multiple Predictions. CVPR2020<br> [2] End-to-End Object Detection with Fully Convolutional Network. CVPR2021<br> [3] Progressive End-to-End Object Detection in Crowded Scenes. CVPR2022<br> ■ 【Peize Sun】【香港大学在读博士】<br> [1] Sparse r-cnn: End-to-end object detection with learnable proposals. CVPR2021<br> [2] What Makes for End-to-End Object Detection? ICML2021</p><h5 id="➢-经典项目" tabindex="-1"><a class="header-anchor" href="#➢-经典项目"><span>➢ 经典项目</span></a></h5><p>○ 上述五篇论文都开源了代码，地址在论文中。第一篇论文开源的代码中包含了纯pytorch实现的Faster-RCNN和Retinanet非常适合初学者入门基于CNN的目标检测算法。<br> ○ 我上传了一个简易版的DETR纯pytorch实现在我的科研方向文件夹中，可以很好的学习DETR原理。<br> ○ 旷视团队的第三篇论文是Peize Sun第一篇论文的改进，通过阅读代码可以从一个角度了解目前研究者改进Detr算法的思路。</p><h3 id="✧-行人重识别-person-re-identification-汪海涛" tabindex="-1"><a class="header-anchor" href="#✧-行人重识别-person-re-identification-汪海涛"><span>✧ 行人重识别（Person Re-identification）-&gt; <code>汪海涛</code></span></a></h3>',10),me={id:"论文汇总-https-github-com-bismex-awesome-person-re-identification-该-repo-内有目前-video-reid-方向的顶会所有论文汇总-包括基本分类、-常用数据库下载、常用-code",tabindex:"-1"},fe={class:"header-anchor",href:"#论文汇总-https-github-com-bismex-awesome-person-re-identification-该-repo-内有目前-video-reid-方向的顶会所有论文汇总-包括基本分类、-常用数据库下载、常用-code"},_e={href:"https://github.com/bismex/Awesome-person-re-identification",target:"_blank",rel:"noopener noreferrer"},Ce=e("h5",{id:"➢-推荐综述-1",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#➢-推荐综述-1"},[e("span",null,"➢ 推荐综述")])],-1),we=e("p",null,[n("[1] Deep Learning for Person Re-identification: A Survey and Outlook, TPAMI 2020(近期的 reid 工作汇总)"),e("br"),n(" [2] Person Re-identification: Past, Present and Future, arXiv 2016(早期的 reid 工作汇总)")],-1),ve=e("ul",null,[e("li",null,"基本看上上面两个 survey 对目前 reid 的发展脉络就可以有一个清晰的把握了"),e("li",null,"看论文的时候 related work 里面的论文都可以参考看一看"),e("li",null,"一些必备的技术点:bagtricks, agw, sbs, pcb, mgn, arcface")],-1),ye=e("h5",{id:"➢-优秀团队-学术大佬-1",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#➢-优秀团队-学术大佬-1"},[e("span",null,"➢ 优秀团队 / 学术大佬")])],-1),Ae={href:"https://www.isee-ai.cn/~zhwshi/",target:"_blank",rel:"noopener noreferrer"},Ve=e("br",null,null,-1),Ee=e("br",null,null,-1),Pe={href:"https://people.ucas.ac.cn/~changhong",target:"_blank",rel:"noopener noreferrer"},Re=e("br",null,null,-1),ke=e("br",null,null,-1),xe=e("h5",{id:"➢-可见光-reid-代表论文",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#➢-可见光-reid-代表论文"},[e("span",null,"➢ 可见光 reid 代表论文")])],-1),De=e("br",null,null,-1),Se=e("br",null,null,-1),Ie={href:"https://github.com/wangguanan/light-reid",target:"_blank",rel:"noopener noreferrer"},Te=e("br",null,null,-1),Me=e("br",null,null,-1),Ne=e("br",null,null,-1),Be=e("h5",{id:"➢-异质-reid-代表论文",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#➢-异质-reid-代表论文"},[e("span",null,"➢ 异质 reid 代表论文")])],-1),Fe=e("p",null,[n("[1] Hi-CMD: Hierarchical Cross-Modality Disentanglement for Visible-Infrared Person Re-Identification，CVPR2020"),e("br"),n(" [2] Cross-Modality Person Re-Identification With Shared-Specific Feature Transfer, CVPR2020"),e("br"),n(" [3] RGB-Infrared Cross-Modality Person Re-Identification via Joint Pixel and Feature Alignment, ICCV2019"),e("br"),n(" [4] Infrared-Visible Cross-Modal Person Re-Identification with an X Modality, AAAI2020")],-1),Le=e("h5",{id:"➢-常用开源项目",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#➢-常用开源项目"},[e("span",null,"➢ 常用开源项目")])],-1),We={href:"https://github.com/michuanhaohao/reid-strong-baseline",target:"_blank",rel:"noopener noreferrer"},qe={href:"https://github.com/JDAI-CV/fast-reid",target:"_blank",rel:"noopener noreferrer"},je=e("h3",{id:"✧-超分辨率重建-super-resolution",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#✧-超分辨率重建-super-resolution"},[e("span",null,"✧ 超分辨率重建（Super-resolution）")])],-1),Ke=r('<h4 id="论文汇总-论文汇总链接-例如github上的-awesome-系列-1" tabindex="-1"><a class="header-anchor" href="#论文汇总-论文汇总链接-例如github上的-awesome-系列-1"><span>论文汇总：论文汇总链接，例如GitHub上的 <code>Awesome</code> 系列</span></a></h4><h5 id="➢-推荐综述-2" tabindex="-1"><a class="header-anchor" href="#➢-推荐综述-2"><span>➢ 推荐综述</span></a></h5><p>[1] Video Super Resolution Based on Deep Learning: A comprehensive survey<br> [2] Deep Learning for Image Super-resolution: A Survey<br> [3] Blind Image Super-Resolution: A Survey and Beyond</p><ul><li>三篇综述分别代表超分领域中的三个小领域：视频超分辨率、单图超分辨率、盲图像超分辨率。</li></ul><h5 id="➢-优秀团队-学术大佬-2" tabindex="-1"><a class="header-anchor" href="#➢-优秀团队-学术大佬-2"><span>➢ 优秀团队 / 学术大佬</span></a></h5><p>■ Xintao Wang:现任腾讯ARC实验室（深圳）研究员。毕业于香港中文大学多媒体实验室。主要研究图像和视频的恢复。<br> 个人主页：https://xinntao.github.io/<br> [1] Wang X, Chan K C K, Yu K, et al. Edvr: Video restoration with enhanced deformable convolutional networks[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops. 2019: 0-0.<br> [2] Wang X, Yu K, Dong C, et al. Recovering realistic texture in image super-resolution by deep spatial feature transform[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 606-615.<br> [3] Wang X, Yu K, Wu S, et al. Esrgan: Enhanced super-resolution generative adversarial networks[C]//Proceedings of the European conference on computer vision (ECCV) workshops. 2018: 0-0.<br> ■ Kelvin C.K. Chan：新加坡南洋理工大学，计算机科学与工程学院，香港中文大学学士学位。<br> 个人主页：https://ckkelvinchan.github.io/<br> [1] Chan K C K, Wang X, Yu K, et al. BasicVSR: The search for essential components in video super-resolution and beyond[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 4947-4956.<br> [2] Chan K C K, Zhou S, Xu X, et al. BasicVSR++: Improving video super-resolution with enhanced propagation and alignment[J]. arXiv preprint arXiv:2104.13371, 2021.<br> [3] Chan K C K, Wang X, Yu K, et al. Understanding deformable alignment in video super-resolution[J]. arXiv preprint arXiv:2009.07265, 2020, 4(3): 4.</p><h5 id="➢-经典论文-推荐加-👍" tabindex="-1"><a class="header-anchor" href="#➢-经典论文-推荐加-👍"><span>➢ 经典论文：（推荐加“👍”）</span></a></h5><ul><li><p>Video Super-Resolution<br> [1] Ward C M, Harguess J, Crabb B, et al. Image quality assessment for determining efficacy and limitations of Super-Resolution Convolutional Neural Network (SRCNN)[C]//Applications of Digital Image Processing XL. International Society for Optics and Photonics, 2017, 10396: 1039605.<br> 简介：该篇论文是深度学习在超分辨率的开山之作。每个入门SR的学者都需要从这一篇论文开始。<br> [2] Liu D, Wang Z, Fan Y, et al. Robust video super-resolution with learned temporal dynamics[C]//Proceedings of the IEEE International Conference on Computer Vision. 2017: 2507-2515.<br> [3] Tian Y, Zhang Y, Fu Y, et al. Tdan: Temporally-deformable alignment network for video super-resolution[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 3360-3369.<br> [4] 👍【Wang X, Chan K C K, Yu K, et al. Edvr: Video restoration with enhanced deformable convolutional networks[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops. 2019: 0-0.<br> [5] Haris M, Shakhnarovich G, Ukita N. Recurrent back-projection network for video super-resolution[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019: 3897-3906.<br> [6] Chan K C K, Wang X, Yu K, et al. BasicVSR: The search for essential components in video super-resolution and beyond[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 4947-4956.<br> [7] Chan K C K, Wang X, Yu K, et al. Understanding deformable alignment in video super-resolution[J]. arXiv preprint arXiv:2009.07265, 2020, 4(3): 4.</p></li><li><p>Blind Image Super-Resolution [1] Zhang K, Zuo W, Zhang L. Learning a single convolutional super-resolution network for multiple degradations[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 3262-3271.<br> [2] Gu J, Lu H, Zuo W, et al. Blind super-resolution with iterative kernel correction[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019: 1604-1613.<br> [3] Wei Y, Gu S, Li Y, et al. Unsupervised real-world image super resolution via domain-distance aware training[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 13385-13394.<br> [4] Shocher A, Cohen N, Irani M. “zero-shot” super-resolution using deep internal learning[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 3118-3126.<br> [5] Hui Z, Li J, Wang X, et al. Learning the Non-differentiable Optimization for Blind Super-Resolution[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 2093-2102.</p></li></ul><h5 id="➢-经典开源项目" tabindex="-1"><a class="header-anchor" href="#➢-经典开源项目"><span>➢ 经典开源项目</span></a></h5><p>○ 【名称】【链接】【简介】</p><p>[1] BasicVSR: https://github.com/xinntao/BasicSR<br> 简介：该项目里包含了很多经典论文的复现，因此可直接将这个开源代码用会就可。</p><h3 id="✧-视频异常检测-video-anomaly-detection-谭明圮" tabindex="-1"><a class="header-anchor" href="#✧-视频异常检测-video-anomaly-detection-谭明圮"><span>✧ 视频异常检测 (Video Anomaly Detection) -&gt; <code>谭明圮</code></span></a></h3>',12),He=r('<h4 id="论文汇总" tabindex="-1"><a class="header-anchor" href="#论文汇总"><span>论文汇总：</span></a></h4><p>[1] https://github.com/fjchange/awesome-video-anomaly-detection 该 repo 内有目前 视频异常检测（VAD） 方向的优秀论文汇总，包括基本分类、 常用数据库下载、 开源code、 综述<br> [2] https://github.com/shot1107/anomaly_detection_papers 该repo 内有异常检测每年顶会的论文，包括但不限于视频异常检测，可参考借鉴。</p><h5 id="➢-认识异常检测" tabindex="-1"><a class="header-anchor" href="#➢-认识异常检测"><span>➢ 认识异常检测</span></a></h5><h6 id="_1-简单介绍-从异常行为检测-视频异常行为检测" tabindex="-1"><a class="header-anchor" href="#_1-简单介绍-从异常行为检测-视频异常行为检测"><span>1. 简单介绍（从异常行为检测--&gt; 视频异常行为检测）</span></a></h6><p>[1] 异常行为检测简介： https://mp.weixin.qq.com/s/UmT0DjFqRPsjv2m28ySvdw<br> [2] 基于深度学习的异常行为检测介绍：https://mp.weixin.qq.com/s/Aghbz4m1eWFCNGgEy8q6Cg<br> [3] 基于深度学习的异常行为检测研究现状： https://mp.weixin.qq.com/s/MwpELRlC1cuDgqn4staAzA<br> [4] 基于深度学习的视频异常行为事件检测简介: https://mp.weixin.qq.com/s/i3Xw2-ivARnF7rBSFtxugw<br> [5] 基于视频的异常行为检测算法介绍: https://mp.weixin.qq.com/s/Dxsc3oCuO0wYkeFubMfSNw</p><h6 id="_2-论文综述" tabindex="-1"><a class="header-anchor" href="#_2-论文综述"><span>2.论文综述：</span></a></h6><p>[1] 邬开俊等. 视频异常检测技术研究进展[J]. 计算机科学与探索, 2022 （中文综述，但没有那么全面，可以有一个初步了解）<br> [2] Bharathkumar Ramachandra et al. A survey of single-scene video anomaly detection (TPAMI 2020)</p><h5 id="➢-优秀团队-学术大佬-3" tabindex="-1"><a class="header-anchor" href="#➢-优秀团队-学术大佬-3"><span>➢ 优秀团队 / 学术大佬</span></a></h5><h6 id="■-高盛华-上海科技大学-视觉与数据智能中心" tabindex="-1"><a class="header-anchor" href="#■-高盛华-上海科技大学-视觉与数据智能中心"><span>■ 高盛华 上海科技大学（视觉与数据智能中心）</span></a></h6><p>[1] A Revisit of Sparse Coding Based Anomaly Detection in Stacked RNN Framework <strong>(ICCV 2017)</strong> --&gt;proposed Shanghaitech dataset.<br> [2] Future Frame Prediction for Anomaly Detection – A New Baseline <strong>(CVPR 2018)</strong><br> [3] Future Frame Prediction for Anomaly Detection <strong>(TPAMI 2022)</strong></p><h6 id="■-radu-ionescu-securifai-university-of-bucharest" tabindex="-1"><a class="header-anchor" href="#■-radu-ionescu-securifai-university-of-bucharest"><span>■ Radu Ionescu SecurifAI/University of Bucharest</span></a></h6><p>[1] Detecting abnormal events in video using Narrowed Normality Clusters <strong>(WACV 2019)</strong><br> [2] Object-centric Auto-encoders and Dummy Anomalies for Abnormal Event Detection in Video <strong>(CVPR 2019)</strong><br> [3] Anomaly Detection in Video via Self-Supervised and Multi-Task Learning <strong>(CVPR 2021)</strong><br> [4] A Background-Agnostic Framework with Adversarial Training for Abnormal Event Detection in Video <strong>(TPAMI 2021)</strong><br> [5] UBnormal New Benchmark for Supervised Open-Set Video Anomaly Detection <strong>(CVPR 2022)</strong> [6] Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection <strong>(CVPR 2022)</strong></p><h5 id="➢-经典论文-推荐加-👍-1" tabindex="-1"><a class="header-anchor" href="#➢-经典论文-推荐加-👍-1"><span>➢ 经典论文：（推荐加“👍”）</span></a></h5><h6 id="■-unsupervised-vad" tabindex="-1"><a class="header-anchor" href="#■-unsupervised-vad"><span>■ Unsupervised VAD</span></a></h6><ul><li><p><strong>Conference Papers</strong><br> [1] Learning Temporal Regularity in Video Sequences <strong>(CVPR 2016)</strong><br> [2] A Revisit of Sparse Coding Based Anomaly Detection in Stacked RNN Framework --&gt;<strong>Proposed Shanghaitech dataset.</strong><br> [2] 👍Future Frame Prediction for Anomaly Detection -- A New Baseline <strong>(CVPR 2018)</strong><br> [3] 👍Memorizing Normality to Detect Anomaly: Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection <strong>(ICCV 2019)</strong> --&gt; <strong>The first to employ memory module on video anomaly detection</strong><br> [4] 👍Object-Centric Auto-Encoders and Dummy Anomalies for Abnormal Event Detection <strong>(CVPR 2019)</strong> --&gt; <strong>The first to combine object detection and vad to achieve object-level anomaly dtection.</strong><br> [5] AnoPCN: Video Anomaly Detection via Deep Predictive Coding Network <strong>(ACM MM 2019)</strong> --&gt; <strong>The first hybrid model</strong><br> [6] 👍Learning Memory-guided Normality for Anomaly Detection <strong>(CVPR 2020)</strong> --&gt; <strong>Based on MemAE</strong><br> [7] Cluster Attention Contrast for Video Anomaly Detection <strong>(ACM MM 2020)</strong> --&gt; <strong>The first to apply Contrastive Learninig</strong><br> [8] 👍Anomaly Detection in Video via Self-Supervised and Multi-Task Learning <strong>(CVPR 2021)</strong> --&gt; <strong>object-level</strong><br> [9] 👍A Hybrid Video Anomaly Detection Framework via Memory-Augmented Flow Reconstruction and Flow-Guided Frame Prediction <strong>(ICCV 2021)</strong> --&gt; <strong>Hybrid model</strong><br> [10] Anomaly Detection in Video Sequence with Appearance-Motion Correspondence (ICCV 2019) --&gt; <strong>Two stream network</strong><br> [11] Video Anomaly Detection and Localization via Gaussian Mixture Fully Convolutional Variational Autoencoder --&gt; <strong>Two stream network</strong><br> [12] Self-supervised Sparse Representation for Video Anomaly Detection <strong>(ECCV 2022)</strong> --&gt; A first attempt to slove unsupervised and weakly supervised VAD [13] Video Anomaly Detection by Solving Decoupled Spatio-Temporal Jigsaw Puzzles <strong>(ECCV 2022)</strong></p></li><li><p><strong>Joural Papers</strong><br> [1] Video Anomaly Detection with Sparse Coding Inspired Deep Neural Networks <strong>(TPAMI 2021)</strong><br> [2] A Background-Agnostic Framework With Adversarial Training for Abnormal Event Detection in Video <strong>(TPAMI 2022)</strong><br> [3] Influence-Aware Attention Networks for Anomaly Detection in Surveillance Videos <strong>(TCSVT 2022)</strong><br> [4] Bidirectional Spatio-Temporal Feature Learning With Multiscale Evaluation for Video Anomaly Detection <strong>(TCSVT 2022)</strong><br> [5] Anomaly Detection With Bidirectional Consistency in Videos <strong>(TNNLS 2022)</strong><br> [6] Variational Abnormal Behavior Detection With Motion Consistency <strong>(TIP 2022)</strong><br> [7] DoTA: Unsupervised Detection of Traffic Anomaly in Driving Videos <strong>(TPAMI 2023)</strong><br> [8] A Hierarchical Spatio-Temporal Graph Convolutional Neural Network for Anomaly Detection in Videos <strong>(TCSVT 2023)</strong><br> [9] Learnable Locality-Sensitive Hashing for Video Anomaly Detection <strong>(TCSVT 2023)</strong><br> [10] A Kalman Variational Autoencoder Model Assisted by Odometric Clustering for Video Frame Prediction and Anomaly Detection <strong>(TIP 2023)</strong><br> [11] Abnormal Event Detection and Localization via Adversarial Event Prediction <strong>(TNNLS 2023)</strong></p></li></ul><h6 id="■-weakly-supervised-vad" tabindex="-1"><a class="header-anchor" href="#■-weakly-supervised-vad"><span>■ Weakly supervised VAD</span></a></h6><p>[1] 👍 Real-world Anomaly Detection in Surveillance Videos <strong>(CVPR 2018)</strong><br> [2] Weakly Supervised Video Anomaly Detection via Center-Guided Discrimative Learning <strong>(ICME 2020)</strong></p><p>[3] Decouple and Resolve: Transformer-Based Models for Online Anomaly Detection From Weakly Labeled Videos <strong>(TIFS 2023)</strong></p><h5 id="➢-经典项目-1" tabindex="-1"><a class="header-anchor" href="#➢-经典项目-1"><span>➢ 经典项目</span></a></h5><p>○ MNAD --&gt; https://github.com/cvlab-yonsei/MNAD 可作为baseline.</p><h5 id="➢-发现的新的有意思的研究方向-explainable-anomaly-detection-ead-可解释性异常检测" tabindex="-1"><a class="header-anchor" href="#➢-发现的新的有意思的研究方向-explainable-anomaly-detection-ead-可解释性异常检测"><span>➢ 发现的新的有意思的研究方向--&gt; Explainable Anomaly Detection (EAD) 可解释性异常检测</span></a></h5><h6 id="_1-definition" tabindex="-1"><a class="header-anchor" href="#_1-definition"><span>1. DEFINITION</span></a></h6><p>The aim of this TASK is to detect and automatically generate high-level explanations of anomalous events in video. Understanding the cause of an anomalous event is crucialas the required response is dependant on its nature andseverity. --&gt; Anomaly Detection &amp; Anoamly Explanation</p><h6 id="_2-related-work" tabindex="-1"><a class="header-anchor" href="#_2-related-work"><span>2. RELATED WORK</span></a></h6><p>[1] Joint Detection and Recounting of Abnormal Events by Learning Deep Generic Knowledge (ICCV 2017)<br> [2] X-MAN: Explaining multiple sources of anomalies in video (CVPR workshop 2021)<br> [3] Discrete neural representations for explainable anomaly detection (WACV 2022)</p><h3 id="✧-航拍图像目标检测-drone-view-object-detection-莫梦竟成" tabindex="-1"><a class="header-anchor" href="#✧-航拍图像目标检测-drone-view-object-detection-莫梦竟成"><span>✧ 航拍图像目标检测（Drone-view Object Detection）-&gt; <code>莫梦竟成</code></span></a></h3>',26),Xe=r('<h4 id="论文汇总-论文汇总链接-例如github上的-awesome-系列-2" tabindex="-1"><a class="header-anchor" href="#论文汇总-论文汇总链接-例如github上的-awesome-系列-2"><span>论文汇总：论文汇总链接，例如GitHub上的 <code>Awesome</code> 系列</span></a></h4><h5 id="➢-推荐综述-3" tabindex="-1"><a class="header-anchor" href="#➢-推荐综述-3"><span>➢ 推荐综述</span></a></h5><p>[1] 【发表于】【年份】【论文名】【团队名】【论文链接】【代码链接】【简介】<br> [2] 【知乎/微信/博客等网页链接】【内容简介】</p><h5 id="➢-优秀团队-学术大佬-4" tabindex="-1"><a class="header-anchor" href="#➢-优秀团队-学术大佬-4"><span>➢ 优秀团队 / 学术大佬</span></a></h5><p>■ 【团队名】【团队链接】【所属机构】【细化方向】<br> [1] 【代表论文】<br> ■ 【大佬名】【个人主页】【所属机构】【细化方向】<br> [1] 【代表论文】</p><h5 id="➢-经典论文-推荐加-👍-2" tabindex="-1"><a class="header-anchor" href="#➢-经典论文-推荐加-👍-2"><span>➢ 经典论文：（推荐加“👍”）</span></a></h5><p>[1] 【发表于】【年份】【论文名】【团队名】【论文链接】【代码链接】【简介】<br> [2] 👍【发表于】【年份】【论文名】【团队名】【论文链接】【代码链接】【简介】</p><h5 id="➢-经典项目-2" tabindex="-1"><a class="header-anchor" href="#➢-经典项目-2"><span>➢ 经典项目</span></a></h5><p>○ 【名称】【链接】【简介】</p><h3 id="✧-小样本目标检测-few-shot-object-detection-陈泰岳" tabindex="-1"><a class="header-anchor" href="#✧-小样本目标检测-few-shot-object-detection-陈泰岳"><span>✧ 小样本目标检测（Few-shot Object Detection）-&gt; <code>陈泰岳</code></span></a></h3>',10),ze=r('<h4 id="论文汇总-论文汇总链接-例如github上的-awesome-系列-3" tabindex="-1"><a class="header-anchor" href="#论文汇总-论文汇总链接-例如github上的-awesome-系列-3"><span>论文汇总：论文汇总链接，例如GitHub上的 <code>Awesome</code> 系列</span></a></h4><h5 id="➢-推荐综述-4" tabindex="-1"><a class="header-anchor" href="#➢-推荐综述-4"><span>➢ 推荐综述</span></a></h5><p>[1] 【发表于】【年份】【论文名】【团队名】【论文链接】【代码链接】【简介】<br> [2] 【知乎/微信/博客等网页链接】【内容简介】</p><h5 id="➢-优秀团队-学术大佬-5" tabindex="-1"><a class="header-anchor" href="#➢-优秀团队-学术大佬-5"><span>➢ 优秀团队 / 学术大佬</span></a></h5><p>■ 【团队名】【团队链接】【所属机构】【细化方向】<br> [1] 【代表论文】<br> ■ 【大佬名】【个人主页】【所属机构】【细化方向】<br> [1] 【代表论文】</p><h5 id="➢-经典论文-推荐加-👍-3" tabindex="-1"><a class="header-anchor" href="#➢-经典论文-推荐加-👍-3"><span>➢ 经典论文：（推荐加“👍”）</span></a></h5><p>[1] 【发表于】【年份】【论文名】【团队名】【论文链接】【代码链接】【简介】<br> [2] 👍【发表于】【年份】【论文名】【团队名】【论文链接】【代码链接】【简介】</p><h5 id="➢-经典项目-3" tabindex="-1"><a class="header-anchor" href="#➢-经典项目-3"><span>➢ 经典项目</span></a></h5><p>○ 【名称】【链接】【简介】</p>',9),Ge=e("p",null,"参考文档：",-1),Oe={href:"https://docs.qq.com/pdf/DR3NNa2xqU0Rld1B2",target:"_blank",rel:"noopener noreferrer"};function Je(Ye,Ue){const t=s("ExternalLinkIcon"),i=s("RouteLink");return c(),h("div",null,[u,g,e("p",null,[n("该文档项目为 Happy Learning 小组的科研入门资料。"),b,n(" ReadMe仅包含基础内容，可作为索引使用，详细内容请见对应文档。"),m,n(" 项目地址: "),e("a",f,[n("http://10.16.104.13:1805/happy-learning/tohappylearning"),o(t)])]),_,e("p",null,[n("冷佳旭 "),e("a",C,[n("https://faculty.cqupt.edu.cn/lengjiaxu/zh_CN/index.htm"),o(t)])]),w,e("p",null,[n("平台使用指南请见 "),e("a",v,[n("http://10.16.104.13:1805/root/users-guide"),o(t)])]),y,e("ol",null,[A,V,E,e("li",null,[n("深度学习基础练习及经典模型 "),o(i,{to:"/browser/learning/3.%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/Torch_learning/"},{default:l(()=>[n("链接入口🔗, 点击进入🔗")]),_:1})]),P]),R,e("ol",null,[e("li",null,[n("基础课程：本硕期间重点掌握 "),k,n(),x,n(),D,n(),S,n(),I,n(" 课程，这里的掌握是要理解它们的本质、作用及物理几何意义，而非应付考试。在学习时抛弃国内出版的死板教材，搜索国内外优秀书籍、公开课、视频进行学习。"),T,n(" 例如，《线性代数》推荐"),e("a",M,[n("《线性代数的本质》系列视频"),o(t)]),e("a",N,[n("https://www.bilibili.com/video/BV1ys411472E"),o(t)]),n("，以及Gilbert Strang 的麻省理工大学公开课视频"),e("a",B,[n("https://www.bilibili.com/video/BV1zx411g7gq"),o(t)]),n("。")]),e("li",null,[n("机器学习：推荐南京大学周志华老师的西瓜书《机器学习》，华为诺亚方舟实验室主任李航老师的《统计学习方法》，斯坦福大学Andrew NG（吴恩达）老师的机器学习课程视频"),e("a",F,[n("https://www.bilibili.com/video/BV164411b7dx"),o(t)]),n("。")]),e("li",null,[n("深度学习：推荐Google研究科学家Ian Goodfellow（Generative Adversarial Nets提出者）的花书《Deep Learning》（有中文译本人民邮电出版社），斯坦福大学李飞飞（ImageNet的提出者）老师的cs231n计算机视觉课程"),e("a",L,[n("https://www.bilibili.com/video/BV1nJ411z7fe"),o(t)]),n("。")]),e("li",null,[n("科研环境：操作系统Linux，主要编程语言Python，主要深度学习框架Pytorch。因此，要掌握Linux的使用方法与常用命令，熟练使用Python语言编程，熟练使用Pytorch深度学习框架搭建网络与深度学习算法。"),W,n(" a. Linux 学习："),e("a",q,[n("https://www.runoob.com/linux/linux-tutorial.html"),o(t)]),n("；"),j,n(" b. Python 学习："),e("a",K,[n("https://www.runoob.com/python3/python3-tutorial.html"),o(t)]),n("；"),H,n(" c. Python 第三方库 Pillow（处理图像）学习："),e("a",X,[n("https://pillow-cn.readthedocs.io/zh_CN/latest/"),o(t)]),n("；"),z,n(" d. Python 第三方库 Numpy（CPU处理多维张量）学习："),e("a",G,[n("https://www.runoob.com/numpy/numpy-tutorial.html"),o(t)]),n("；"),O,n(" e. 深度学习框架Pytorch（使用Python编程，GPU处理多维张量，提供深度学习API）学习："),e("a",J,[n("https://pytorch.apachecn.org/docs/1.4/"),o(t)]),n("。")])]),Y,e("ol",null,[e("li",null,[n("科学上网：一个可用稳定的上谷歌（翻墙）工具是必须的，推荐："),e("a",U,[n("https://geckoiplc.org/register?aff=nxkYWh33"),o(t)]),n("，使用方法该网站有教程")]),e("li",null,[n("检索论文：GoogleScholar："),e("a",Z,[n("https://scholar.google.com/"),o(t)]),n("（需翻墙）")]),e("li",null,[n("下载论文："),Q,n(" a. IEEE："),e("a",$,[n("https://ieeexplore.ieee.org/Xplore/home.jsp"),o(t)]),n("；"),ee,n(" b. ScienceDirect："),e("a",ne,[n("https://www.sciencedirect.com/"),o(t)]),n("；"),oe,n(" c. SpringerLink："),e("a",te,[n("https://link.springer.com/"),o(t)]),n("；"),re,n(" d. arXiv："),e("a",ae,[n("https://arxiv.org/"),o(t)]),n("占坑网站，最新的文章会发表在上面占坑，但是良莠不齐，免费下载，翻墙会快；"),ie,n(" e. Sci-Hub："),e("a",se,[n("https://www.sci-hub.ren/"),o(t)]),n("不在学校内又想下载IEEE等版权收费文章？Sci-Hub是神器，网站宣言...to remove all the barriers in the way of science，地址可能会变，因为一直被告。")]),e("li",null,[n("管理论文：Mendely："),e("a",le,[n("https://www.mendeley.com/"),o(t)]),n("；Endnotes："),e("a",de,[n("https://www.endnote.com/"),o(t)]),n("；Zotero："),e("a",ce,[n("https://www.zotero.org/"),o(t)]),n("；自己选择。")]),e("li",null,[n("撰写论文：LaTex环境安装："),e("a",he,[n("http://tug.org/texlive/"),o(t)]),n("；按着网站指导来。也可以使用在线的LaTex编辑工具如Overleaf："),e("a",pe,[n("https://www.overleaf.com/login"),o(t)]),n("。")]),ue,e("li",null,[n("代码编辑：VSCode（Visual Studio Code）："),e("a",ge,[n("https://code.visualstudio.com/"),o(t)]),n("； 你想要的代码编辑功能都能通过VSCode+插件实现。 常用VSCode插件：LaTex Workshop（用VSCode写论文，前提得先装好LaTex环境）、Remote-SSH（用VSCode直接浏览编辑远程服务器上的代码和图片）、One Dark Pro（让VSCode更好看）、Bracket Pair Colorizer 2（让代码每一级括号带不同的颜色，括号再也不会不成对报错了）、Code Spell Checker（检查你的拼写是否有错误）、indent-rainbow（不同级的缩进带不同颜色，对Python来说很有用）、Python（可以直接在VSCode调试Python程序，前提得先装好Python环境）。")]),e("li",null,[n("服务器后台运行管理工具tmux "),o(i,{to:"/browser/learning/2.%E7%A7%91%E7%A0%94%E5%B7%A5%E5%85%B7/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%90%8E%E5%8F%B0%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7tmux.html"},{default:l(()=>[n("链接入口🔗, 点击进入🔗")]),_:1}),n("。")])]),be,e("h4",me,[e("a",fe,[e("span",null,[n("论文汇总: "),e("a",_e,[n("https://github.com/bismex/Awesome-person-re-identification"),o(t)]),n("，该 repo 内有目前 video reid 方向的顶会所有论文汇总，包括基本分类、 常用数据库下载、常用 code")])])]),Ce,we,ve,ye,e("p",null,[n("■ 郑伟诗 Wei-Shi Zheng 中山大学智能科学与系统实验室(iSEE) "),e("a",Ae,[n("https://www.isee-ai.cn/~zhwshi/"),o(t)]),Ve,n(' [1] J. Yang, W. -S. Zheng, Q. Yang, Y. -C. Chen and Q. Tian, "Spatial-Temporal Graph Convolutional Network for Video-Based Person Re-Identification," 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2020, pp. 3286-3296, doi: 10.1109/CVPR42600.2020.00335.'),Ee,n(' [2] J. Yang et al., "Learning to Know Where to See: A Visibility-Aware Approach for Occluded Person Re-identification," 2021 IEEE/CVF International Conference on Computer Vision (ICCV), 2021, pp. 11865-11874, doi: 10.1109/ICCV48922.2021.01167.')]),e("p",null,[n("■ 常虹 Chang Hong 中国科学院计算机技术研究院(CAS) "),e("a",Pe,[n("https://people.ucas.ac.cn/~changhong"),o(t)]),Re,n(' [1] R. Hou, B. Ma, H. Chang, X. Gu, S. Shan and X. Chen, "VRSTC: Occlusion-Free Video Person Re-Identification," 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019, pp. 7176-7185, doi: 10.1109/CVPR.2019.00735.'),ke,n(' [2] R. Hou, H. Chang, B. Ma, R. Huang and S. Shan, "BiCnet-TKS: Learning Efficient Spatial-Temporal Representation for Video Person Re-Identification," 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021, pp. 2014-2023, doi: 10.1109/CVPR46437.2021.00205.')]),xe,e("p",null,[n("[1] Joint Disentangling and Adaptation for Cross-Domain Person Re-Identification, ECCV2020"),De,n(" [2] Identity-Guided Human Semantic Parsing for Person Re-Identification, ECCV2020"),Se,n(" [3] Faster Person Re-Identification, ECCV20 (轻量级 reid， "),e("a",Ie,[n("https://github.com/wangguanan/light-reid"),o(t)]),n(" )"),Te,n(" [4] Joint Visual and Temporal Consistency for Unsupervised Domain Adaptive Person Re-Identification, ECCV2020"),Me,n(" [5] Re-Ranking Person Re-Identification With k-Reciprocal Encoding， CVPR2017(将 reranking 应用到 reid，涨点显著)"),Ne,n(" [6] Person Re-Identification in the Wild, CVPR2017(从检测到识别)")]),Be,Fe,Le,e("ul",null,[e("li",null,[n("strong baseline: "),e("a",We,[n("https://github.com/michuanhaohao/reid-strong-baseline"),o(t)])]),e("li",null,[n("FAST-REID: "),e("a",qe,[n("https://github.com/JDAI-CV/fast-reid"),o(t)])])]),je,a("模版"),Ke,a("模版"),He,a("模版"),Xe,a("模版"),ze,e("blockquote",null,[Ge,e("ol",null,[e("li",null,[n("【在iiplab做科研】 "),e("a",Oe,[n("https://docs.qq.com/pdf/DR3NNa2xqU0Rld1B2"),o(t)]),n("，特别感谢～")])])])])}const $e=d(p,[["render",Je],["__file","README (2).html.vue"]]),en=JSON.parse(`{"path":"/browser/learning/README%20(2).html","title":"ReadMe🧐","lang":"en-US","frontmatter":{"description":"ReadMe🧐 介绍 该文档项目为 Happy Learning 小组的科研入门资料。 ReadMe仅包含基础内容，可作为索引使用，详细内容请见对应文档。 项目地址: http://10.16.104.13:1805/happy-learning/tohappylearning 小组老大 冷佳旭 https://faculty.cqupt.edu.c...","head":[["meta",{"property":"og:url","content":"https://2-mo.github.io/browser/learning/README%20(2).html"}],["meta",{"property":"og:site_name","content":"Tiu Mo's Blog"}],["meta",{"property":"og:title","content":"ReadMe🧐"}],["meta",{"property":"og:description","content":"ReadMe🧐 介绍 该文档项目为 Happy Learning 小组的科研入门资料。 ReadMe仅包含基础内容，可作为索引使用，详细内容请见对应文档。 项目地址: http://10.16.104.13:1805/happy-learning/tohappylearning 小组老大 冷佳旭 https://faculty.cqupt.edu.c..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2024-09-01T07:46:43.000Z"}],["meta",{"property":"article:author","content":"Tiu Mo"}],["meta",{"property":"article:modified_time","content":"2024-09-01T07:46:43.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"ReadMe🧐\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2024-09-01T07:46:43.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Tiu Mo\\",\\"url\\":\\"https://2-mo.github.io\\"}]}"]]},"headers":[{"level":2,"title":"介绍","slug":"介绍","link":"#介绍","children":[]},{"level":2,"title":"小组老大","slug":"小组老大","link":"#小组老大","children":[]},{"level":2,"title":"使用指南","slug":"使用指南","link":"#使用指南","children":[]},{"level":2,"title":"文档总览","slug":"文档总览","link":"#文档总览","children":[]},{"level":2,"title":"新生入门","slug":"新生入门","link":"#新生入门","children":[]},{"level":2,"title":"科研基础","slug":"科研基础","link":"#科研基础","children":[]},{"level":2,"title":"科研工具","slug":"科研工具","link":"#科研工具","children":[]},{"level":2,"title":"科研方向","slug":"科研方向","link":"#科研方向","children":[{"level":3,"title":"✧ 行人检测（Person Detection）-> 高峰 (博士)","slug":"✧-行人检测-person-detection-高峰-博士","link":"#✧-行人检测-person-detection-高峰-博士","children":[]},{"level":3,"title":"✧ 行人重识别（Person Re-identification）-> 汪海涛","slug":"✧-行人重识别-person-re-identification-汪海涛","link":"#✧-行人重识别-person-re-identification-汪海涛","children":[]},{"level":3,"title":"✧ 超分辨率重建（Super-resolution）","slug":"✧-超分辨率重建-super-resolution","link":"#✧-超分辨率重建-super-resolution","children":[]},{"level":3,"title":"✧ 视频异常检测 (Video Anomaly Detection) -> 谭明圮","slug":"✧-视频异常检测-video-anomaly-detection-谭明圮","link":"#✧-视频异常检测-video-anomaly-detection-谭明圮","children":[]},{"level":3,"title":"✧ 航拍图像目标检测（Drone-view Object Detection）-> 莫梦竟成","slug":"✧-航拍图像目标检测-drone-view-object-detection-莫梦竟成","link":"#✧-航拍图像目标检测-drone-view-object-detection-莫梦竟成","children":[]},{"level":3,"title":"✧ 小样本目标检测（Few-shot Object Detection）-> 陈泰岳","slug":"✧-小样本目标检测-few-shot-object-detection-陈泰岳","link":"#✧-小样本目标检测-few-shot-object-detection-陈泰岳","children":[]}]}],"git":{"createdTime":1720419990000,"updatedTime":1725176803000,"contributors":[{"name":"2-mo","email":"1982800736@qq.com","commits":1}]},"readingTime":{"minutes":14.53,"words":4360},"filePathRelative":"browser/learning/README (2).md","localizedDate":"July 8, 2024","excerpt":"\\n<h2>介绍</h2>\\n<p>该文档项目为 Happy Learning 小组的科研入门资料。<br>\\nReadMe仅包含基础内容，可作为索引使用，详细内容请见对应文档。<br>\\n项目地址: <a href=\\"http://10.16.104.13:1805/happy-learning/tohappylearning\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">http://10.16.104.13:1805/happy-learning/tohappylearning</a></p>\\n<h2>小组老大</h2>\\n<p>冷佳旭  <a href=\\"https://faculty.cqupt.edu.cn/lengjiaxu/zh_CN/index.htm\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">https://faculty.cqupt.edu.cn/lengjiaxu/zh_CN/index.htm</a></p>","autoDesc":true}`);export{$e as comp,en as data};
