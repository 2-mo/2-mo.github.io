import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{o,c as i,a as e}from"./app-CkzG2MlB.js";const n={},a=e("p",null,"Awesome-Multimodal-Large-Language-Models https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models",-1),d=e("p",null,"VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs",-1),r=e("p",null,"https://github.com/DAMO-NLP-SG/VideoLLaMA2",-1),l=e("p",null,"AskVideos-VideoCLIP https://github.com/AskYoutubeAI/AskVideos-VideoCLIP",-1),s=e("p",null,"InternVideo2: Scaling Video Foundation Models for Multimodal Video Understanding https://github.com/OpenGVLab/InternVideo",-1),m=e("p",null,"INTERNVIDEO2: SCALING VIDEO FOUNDATION MODELS FOR MULTIMODAL VIDEO UNDERSTANDING https://github.com/OpenGVLab/InternVideo2",-1),p=e("p",null,"InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation https://github.com/OpenGVLab/InternVideo/tree/main/Data/InternVid",-1),c=e("p",null,"ViCLIP: a video-text representation learning model trained on InternVid https://github.com/OpenGVLab/InternVideo/tree/main/InternVideo1/Pretrain/ViCLIP",-1),u=[a,d,r,l,s,m,p,c];function g(h,L){return o(),i("div",null,u)}const V=t(n,[["render",g],["__file","videollm.html.vue"]]),_=JSON.parse(`{"path":"/discover/uncover/videollm.html","title":"","lang":"en-US","frontmatter":{"description":"Awesome-Multimodal-Large-Language-Models https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understa...","head":[["meta",{"property":"og:url","content":"https://2-mo.github.io/discover/uncover/videollm.html"}],["meta",{"property":"og:site_name","content":"Tiu Mo's Blog"}],["meta",{"property":"og:description","content":"Awesome-Multimodal-Large-Language-Models https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understa..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2024-09-01T07:46:43.000Z"}],["meta",{"property":"article:author","content":"Tiu Mo"}],["meta",{"property":"article:modified_time","content":"2024-09-01T07:46:43.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2024-09-01T07:46:43.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Tiu Mo\\",\\"url\\":\\"https://2-mo.github.io\\"}]}"]]},"headers":[],"git":{"createdTime":1720430278000,"updatedTime":1725176803000,"contributors":[{"name":"2-mo","email":"1982800736@qq.com","commits":1}]},"readingTime":{"minutes":0.27,"words":80},"filePathRelative":"discover/uncover/videollm.md","localizedDate":"July 8, 2024","excerpt":"<p>Awesome-Multimodal-Large-Language-Models\\nhttps://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models</p>\\n<p>VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs</p>\\n<p>https://github.com/DAMO-NLP-SG/VideoLLaMA2</p>\\n<p>AskVideos-VideoCLIP\\nhttps://github.com/AskYoutubeAI/AskVideos-VideoCLIP</p>","autoDesc":true}`);export{V as comp,_ as data};
