import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{o as p,c as e,f as o}from"./app-COJaJ9Zq.js";const i={},n=o("<p>1、 题目： MSC-Bench: Benchmarking and Analyzing Multi-Sensor Corruption for Driving Perception</p><p>链接： https://t.zsxq.com/BRSA3</p><p>简介： MSC-Bench: 第一个针对多传感器自动驾驶感知模型在各种传感器损坏情况下的鲁棒性进行评估的综合基准</p><p>时间： 2025-01-10T23:52:48.526+0800</p><p>2、 题目： Hidden Biases of End-to-End Driving Datasets</p><p>链接：https://t.zsxq.com/BRSA3</p><p>简介： 2024 CARLA挑战赛中的地图和传感器赛道上排名第一和第二！Bench2Drive测试路线中SOTA！</p><p>时间： 2024-12-13T12:01:19.839+0800</p><p>3、 题目： Multi-cam Multi-map Visual Inertial Localization: System, Validation and Dataset</p><p>链接： https://t.zsxq.com/Pvi0i</p><p>简介： 一种多摄像头多地图视觉惯性定位系统</p><p>时间： 2024-12-08T00:04:34.943+0800</p><p>4、 题目： OpenAD: Open-World Autonomous Driving Benchmark for 3D Object Detection</p><p>链接： https://t.zsxq.com/U7foq</p><p>简介： 首个针对3D目标检测的现实世界开放世界自动驾驶基准</p><p>时间： 2024-11-28T14:12:50.201+0800</p><p>5、 题目： V2X-Radar: A Multi-modal Dataset with 4D Radar for Cooperative Perception</p><p>链接：https://t.zsxq.com/cbO6x</p><p>简介： 全球首个集成4D Radar并面向真实场景的多模态车路协同感知数据集</p><p>时间： 2024-11-19T21:19:52.213+0800</p><p>6、 题目： V2X-R: Cooperative LiDAR-4D Radar Fusion for 3D Object Detection with Denoising Diffusion</p><p>链接： https://t.zsxq.com/3Xm4K</p><p>简介： V2X-R: 首个结合LiDAR、相机和4D Radar的V2X模拟数据集</p><p>时间： 2024-11-14T22:38:05.292+0800</p><p>7、 题目： Holistic Autonomous Driving Understanding by Bird’s-Eye-View Injected Multi-Modal Large Models</p><p>链接： https://t.zsxq.com/ncOgu</p><p>简介： 通过BEV注入多模态大模型对自动驾驶的整体理解：BEV-InMLLM整合了多视图、空间意识和时间语义，以增强在NuInstruct任务上的MLLMs的能力</p><p>时间： 2024-01-03T21:23:08.634+0800</p><p>8、 题目： ROAD-Waymo: Action Awareness at Scale for Autonomous Driving</p><p>链接： https://t.zsxq.com/8T9mw</p><p>简介： ROAD-Waymo，一个广泛的数据集，用于开发和评估道路场景中agents、动作、位置和事件检测技术，该数据集基于Waymo Open数据集</p><p>时间： 2024-11-06T21:58:38.047+0800</p><p>9、 题目： Adver-City: Open-Source Multi-Modal Dataset for Collaborative Perception Under Adverse Weather Conditions</p><p>链接：https://t.zsxq.com/xtCoc</p><p>简介： 第一个专注于恶劣天气条件的开源合成协同感知数据集</p><p>时间： 2024-10-15T23:59:12.411+0800</p><p>10、 题目： TLD: A Vehicle Tail Light signal Dataset and Benchmark</p><p>链接： https://t.zsxq.com/c2Fkk</p><p>简介： 转向灯、刹车灯数据集来了！</p><p>时间： 2024-09-06T23:22:06.957+0800</p><p>11、 题目： WayveScenes101: A Dataset and Benchmark for Novel View Synthesis in Autonomous Driving</p><p>链接： https://t.zsxq.com/VHTIL</p><p>简介： WayveScenes101: 该数据集专注于包含众多动态和可变形元素、几何形状和纹理变化的复杂驾驶场景。数据集包含101个驾驶场景，涵盖广泛的环境条件和驾驶情景</p><p>时间： 2024-07-14T22:20:58.691+0800</p><p>12、 题目： SID: Stereo Image Dataset for Autonomous Driving in Adverse Conditions</p><p>链接： https://t.zsxq.com/p9xIi</p><p>简介： SID：用于恶劣条件下自动驾驶的立体图像数据集</p><p>时间： 2024-07-09T23:28:37.587+0800</p><p>13、 题目： DurLAR: A High-Fidelity 128-Channel LiDAR Dataset with Panoramic Ambient and Reflectivity Imagery for Multi-Modal Autonomous Driving Applications</p><p>链接：https://t.zsxq.com/4ntGo</p><p>简介： DurLAR：一个高保真度的128通道3D激光雷达数据集</p><p>时间： 2024-06-17T23:27:08.364+0800</p><p>14、 题目： Multiagent Multitraversal Multimodal Self-Driving: Open MARS Dataset</p><p>链接：https://t.zsxq.com/cdN4u</p><p>简介： 纽约大学联合自动驾驶公司May Mobility，推出了MARS数据集，该数据集统一了多agent、多遍历和多模态自动驾驶研究的场景</p><p>时间： 2024-06-16T09:52:47.868+0800</p><p>15、 题目： SEVD: Synthetic Event-based Vision Dataset for Ego and Fixed Traffic Perception</p><p>链接： https://t.zsxq.com/XGIKB</p><p>简介： 首创的多视角自车和固定感知的基于事件的合成数据集</p><p>时间： 2024-04-27T09:43:05.766+0800</p><p>16、 题目： PLoc: A New Evaluation Criterion Based on Physical Location for Autonomous Driving Datasets</p><p>链接：https://t.zsxq.com/xypV4</p><p>简介： PLoc：一种新的基于物理位置的自动驾驶数据集评估标准</p><p>时间： 2024-04-06T00:09:04.617+0800</p><p>17、 题目： CORP: A Multi-Modal Dataset for Campus-Oriented Roadside Perception Tasks</p><p>链接： https://t.zsxq.com/45W4L</p><p>简介： CORP：专为校园场景下的多模态路边感知任务量身定制的首个公共基准数据集</p><p>时间： 2024-04-05T23:57:47.758+0800</p><p>18、 题目： Dataset and Benchmark: Novel Sensors for Autonomous Vehicle Perception</p><p>链接： https://t.zsxq.com/jvN0b</p><p>简介： 用于自动驾驶汽车感知的新型传感器有哪些？来看看这份NSAVP数据集和基准</p><p>时间： 2024-01-27T10:40:46.045+0800</p><p>19、 题目： A Survey on Autonomous Driving Datasets: Data Statistic, Annotation, and Outlook</p><p>链接：https://t.zsxq.com/HZCx9</p><p>简介： 200+自动驾驶数据集全面调研！</p><p>时间： 2024-01-04T22:54:54.556+0800</p><p>20、 题目：英伟达和卡内基梅隆大学最新！V2V-LLM：基于多模态大语言模型的车对车协作式自动驾驶</p><p>链接：https://t.zsxq.com/07jyx</p><p>简介： 一种基于LLM的协作式自动驾驶新框架，并配套发布首个面向车对车问答（V2V-QA）的数据集与评测基准</p><p>https://mp.weixin.qq.com/s/gBmrPWyK77wUzsftx2Tw9w</p><p>https://mp.weixin.qq.com/s/IznY5Zpk_dhOk-oyx6Nnsg</p><p>谈谈DeepSeek对自动驾驶的影响</p><p>https://drive-bench.github.io/ Are VLMs Ready for Autonomous Driving? An Empirical Study from the Reliability, Data, and Metric Perspectives</p>",83),a=[n];function s(r,c){return p(),e("div",null,a)}const l=t(i,[["render",s],["__file","ad_datasets.html.vue"]]),h=JSON.parse(`{"path":"/polaris/ad_datasets.html","title":"","lang":"en-US","frontmatter":{"description":"1、 题目： MSC-Bench: Benchmarking and Analyzing Multi-Sensor Corruption for Driving Perception 链接： https://t.zsxq.com/BRSA3 简介： MSC-Bench: 第一个针对多传感器自动驾驶感知模型在各种传感器损坏情况下的鲁棒性进行评估的综合基准...","head":[["meta",{"property":"og:url","content":"https://2-mo.github.io/polaris/ad_datasets.html"}],["meta",{"property":"og:site_name","content":"Tiu Mo's Blog"}],["meta",{"property":"og:description","content":"1、 题目： MSC-Bench: Benchmarking and Analyzing Multi-Sensor Corruption for Driving Perception 链接： https://t.zsxq.com/BRSA3 简介： MSC-Bench: 第一个针对多传感器自动驾驶感知模型在各种传感器损坏情况下的鲁棒性进行评估的综合基准..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-03-13T13:38:09.000Z"}],["meta",{"property":"article:author","content":"Tiu Mo"}],["meta",{"property":"article:modified_time","content":"2025-03-13T13:38:09.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-03-13T13:38:09.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Tiu Mo\\",\\"url\\":\\"https://2-mo.github.io\\"}]}"]]},"headers":[],"git":{"createdTime":1741005407000,"updatedTime":1741873089000,"contributors":[{"name":"Tiu Mo","email":"1982800736@qq.com","commits":2}]},"readingTime":{"minutes":4.07,"words":1222},"filePathRelative":"polaris/ad_datasets.md","localizedDate":"March 3, 2025","excerpt":"<p>1、 题目： MSC-Bench: Benchmarking and Analyzing Multi-Sensor Corruption for Driving Perception</p>\\n<p>链接： https://t.zsxq.com/BRSA3</p>\\n<p>简介： MSC-Bench: 第一个针对多传感器自动驾驶感知模型在各种传感器损坏情况下的鲁棒性进行评估的综合基准</p>\\n<p>时间： 2025-01-10T23:52:48.526+0800</p>\\n<p>2、 题目： Hidden Biases of End-to-End Driving Datasets</p>\\n<p>链接：https://t.zsxq.com/BRSA3</p>","autoDesc":true}`);export{l as comp,h as data};
