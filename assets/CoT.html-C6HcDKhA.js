import{_ as r}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as a,o as l,c as i,e as s,a as e,b as n,d as t}from"./app-BpePyK3c.js";const p={},c=e("h2",{id:"_111",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_111"},[e("span",null,"111")])],-1),g=e("h2",{id:"类比提示-analogical-prompting",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#类比提示-analogical-prompting"},[e("span",null,'"类比提示"(analogical prompting)')])],-1),m=e("strong",null,"Emergent Analogical Reasoning in Large Language Models",-1),h=e("br",null,null,-1),d=e("small",null," (NHB'23, Nature Human Behaviour 2023) @University of California ",-1),u={href:"https://www.nature.com/articles/s41562-023-01659-w",target:"_blank",rel:"noopener noreferrer"},_={href:"https://arxiv.org/pdf/2212.09196",target:"_blank",rel:"noopener noreferrer"},f={href:"https://github.com/taylorwwebb/emergent_analogies_LLM",target:"_blank",rel:"noopener noreferrer"},b=e("strong",null,"LARGE LANGUAGE MODELS AS ANALOGICAL REASONERS",-1),L=e("br",null,null,-1),C=e("small",null," (ICLR'24) @Google DeepMind ",-1),v={href:"https://arxiv.org/abs/2310.01714",target:"_blank",rel:"noopener noreferrer"},A={href:"https://mp.weixin.qq.com/s/EcOMx7FCE-oiE0_4OqC1bA",target:"_blank",rel:"noopener noreferrer"};function E(T,y){const o=a("ExternalLinkIcon");return l(),i("div",null,[s(" markdownlint-disable MD033 "),c,g,e("ul",null,[e("li",null,[e("p",null,[m,n(),h,d,e("a",u,[n("[Paper]"),t(o)]),e("a",_,[n("[arXiv]"),t(o)]),e("a",f,[n("[Code]"),t(o)])])]),e("li",null,[e("p",null,[b,n(),L,C,e("a",v,[n("[arXiv]"),t(o)]),e("a",A,[n("[推文]"),t(o)])])])])])}const x=r(p,[["render",E],["__file","CoT.html.vue"]]),M=JSON.parse(`{"path":"/uncover/CoT.html","title":"ICL/CoT/GoT","lang":"en-US","frontmatter":{"title":"ICL/CoT/GoT","description":"111 \\"类比提示\\"(analogical prompting) Emergent Analogical Reasoning in Large Language Models (NHB'23, Nature Human Behaviour 2023) @University of California [Paper] [arXiv] [Code] LA...","head":[["meta",{"property":"og:url","content":"https://2-mo.github.io/uncover/CoT.html"}],["meta",{"property":"og:site_name","content":"Tiu Mo's Blog"}],["meta",{"property":"og:title","content":"ICL/CoT/GoT"}],["meta",{"property":"og:description","content":"111 \\"类比提示\\"(analogical prompting) Emergent Analogical Reasoning in Large Language Models (NHB'23, Nature Human Behaviour 2023) @University of California [Paper] [arXiv] [Code] LA..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2024-07-06T12:00:24.000Z"}],["meta",{"property":"article:author","content":"Tiu Mo"}],["meta",{"property":"article:modified_time","content":"2024-07-06T12:00:24.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"ICL/CoT/GoT\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2024-07-06T12:00:24.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Tiu Mo\\",\\"url\\":\\"https://2-mo.github.io\\"}]}"]]},"headers":[{"level":2,"title":"111","slug":"_111","link":"#_111","children":[]},{"level":2,"title":"\\"类比提示\\"(analogical prompting)","slug":"类比提示-analogical-prompting","link":"#类比提示-analogical-prompting","children":[]}],"git":{"createdTime":1720267224000,"updatedTime":1720267224000,"contributors":[{"name":"2-mo","email":"1982800736@qq.com","commits":1}]},"readingTime":{"minutes":0.21,"words":64},"filePathRelative":"uncover/CoT.md","localizedDate":"July 6, 2024","excerpt":"<!-- markdownlint-disable MD033 -->\\n<h2>111</h2>\\n<h2>\\"类比提示\\"(analogical prompting)</h2>\\n<ul>\\n<li>\\n<p><strong>Emergent Analogical Reasoning in Large Language Models</strong> <br>\\n<small> (NHB'23, Nature Human Behaviour 2023) @University of California </small>\\n<a href=\\"https://www.nature.com/articles/s41562-023-01659-w\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">[Paper]</a>\\n<a href=\\"https://arxiv.org/pdf/2212.09196\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">[arXiv]</a>\\n<a href=\\"https://github.com/taylorwwebb/emergent_analogies_LLM\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">[Code]</a></p>\\n</li>\\n<li>\\n<p><strong>LARGE LANGUAGE MODELS AS ANALOGICAL REASONERS</strong> <br>\\n<small> (ICLR'24) @Google DeepMind </small>\\n<a href=\\"https://arxiv.org/abs/2310.01714\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">[arXiv]</a>\\n<a href=\\"https://mp.weixin.qq.com/s/EcOMx7FCE-oiE0_4OqC1bA\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">[推文]</a></p>\\n</li>\\n</ul>","autoDesc":true}`);export{x as comp,M as data};
