1、 题目： MSC-Bench: Benchmarking and Analyzing Multi-Sensor Corruption for Driving Perception

链接： https://t.zsxq.com/BRSA3

简介： MSC-Bench: 第一个针对多传感器自动驾驶感知模型在各种传感器损坏情况下的鲁棒性进行评估的综合基准

时间： 2025-01-10T23:52:48.526+0800

2、 题目： Hidden Biases of End-to-End Driving Datasets

链接：https://t.zsxq.com/BRSA3

简介： 2024 CARLA挑战赛中的地图和传感器赛道上排名第一和第二！Bench2Drive测试路线中SOTA！

时间： 2024-12-13T12:01:19.839+0800

3、 题目： Multi-cam Multi-map Visual Inertial Localization: System, Validation and Dataset

链接： https://t.zsxq.com/Pvi0i

简介： 一种多摄像头多地图视觉惯性定位系统

时间： 2024-12-08T00:04:34.943+0800

4、 题目： OpenAD: Open-World Autonomous Driving Benchmark for 3D Object Detection

链接： https://t.zsxq.com/U7foq

简介： 首个针对3D目标检测的现实世界开放世界自动驾驶基准

时间： 2024-11-28T14:12:50.201+0800

5、 题目： V2X-Radar: A Multi-modal Dataset with 4D Radar for Cooperative Perception

链接：https://t.zsxq.com/cbO6x

简介： 全球首个集成4D Radar并面向真实场景的多模态车路协同感知数据集

时间： 2024-11-19T21:19:52.213+0800

6、 题目： V2X-R: Cooperative LiDAR-4D Radar Fusion for 3D Object Detection with Denoising Diffusion

链接： https://t.zsxq.com/3Xm4K

简介： V2X-R: 首个结合LiDAR、相机和4D Radar的V2X模拟数据集

时间： 2024-11-14T22:38:05.292+0800

7、 题目： Holistic Autonomous Driving Understanding by Bird’s-Eye-View Injected Multi-Modal Large Models

链接： https://t.zsxq.com/ncOgu

简介： 通过BEV注入多模态大模型对自动驾驶的整体理解：BEV-InMLLM整合了多视图、空间意识和时间语义，以增强在NuInstruct任务上的MLLMs的能力

时间： 2024-01-03T21:23:08.634+0800

8、 题目： ROAD-Waymo: Action Awareness at Scale for Autonomous Driving

链接： https://t.zsxq.com/8T9mw

简介： ROAD-Waymo，一个广泛的数据集，用于开发和评估道路场景中agents、动作、位置和事件检测技术，该数据集基于Waymo Open数据集

时间： 2024-11-06T21:58:38.047+0800

9、 题目： Adver-City: Open-Source Multi-Modal Dataset for Collaborative Perception Under Adverse Weather Conditions

链接：https://t.zsxq.com/xtCoc

简介： 第一个专注于恶劣天气条件的开源合成协同感知数据集

时间： 2024-10-15T23:59:12.411+0800

10、 题目： TLD: A Vehicle Tail Light signal Dataset and Benchmark

链接： https://t.zsxq.com/c2Fkk

简介： 转向灯、刹车灯数据集来了！

时间： 2024-09-06T23:22:06.957+0800

11、 题目： WayveScenes101: A Dataset and Benchmark for Novel View Synthesis in Autonomous Driving

链接： https://t.zsxq.com/VHTIL

简介： WayveScenes101: 该数据集专注于包含众多动态和可变形元素、几何形状和纹理变化的复杂驾驶场景。数据集包含101个驾驶场景，涵盖广泛的环境条件和驾驶情景

时间： 2024-07-14T22:20:58.691+0800

12、 题目： SID: Stereo Image Dataset for Autonomous Driving in Adverse Conditions

链接： https://t.zsxq.com/p9xIi

简介： SID：用于恶劣条件下自动驾驶的立体图像数据集

时间： 2024-07-09T23:28:37.587+0800

13、 题目： DurLAR: A High-Fidelity 128-Channel LiDAR Dataset with Panoramic Ambient and Reflectivity Imagery for Multi-Modal Autonomous Driving Applications

链接：https://t.zsxq.com/4ntGo

简介： DurLAR：一个高保真度的128通道3D激光雷达数据集

时间： 2024-06-17T23:27:08.364+0800

14、 题目： Multiagent Multitraversal Multimodal Self-Driving: Open MARS Dataset

链接：https://t.zsxq.com/cdN4u

简介： 纽约大学联合自动驾驶公司May Mobility，推出了MARS数据集，该数据集统一了多agent、多遍历和多模态自动驾驶研究的场景

时间： 2024-06-16T09:52:47.868+0800

15、 题目： SEVD: Synthetic Event-based Vision Dataset for Ego and Fixed Traffic Perception

链接： https://t.zsxq.com/XGIKB

简介： 首创的多视角自车和固定感知的基于事件的合成数据集

时间： 2024-04-27T09:43:05.766+0800

16、 题目： PLoc: A New Evaluation Criterion Based on Physical Location for Autonomous Driving Datasets

链接：https://t.zsxq.com/xypV4

简介： PLoc：一种新的基于物理位置的自动驾驶数据集评估标准

时间： 2024-04-06T00:09:04.617+0800

17、 题目： CORP: A Multi-Modal Dataset for Campus-Oriented Roadside Perception Tasks

链接： https://t.zsxq.com/45W4L

简介： CORP：专为校园场景下的多模态路边感知任务量身定制的首个公共基准数据集

时间： 2024-04-05T23:57:47.758+0800

18、 题目： Dataset and Benchmark: Novel Sensors for Autonomous Vehicle Perception

链接： https://t.zsxq.com/jvN0b

简介： 用于自动驾驶汽车感知的新型传感器有哪些？来看看这份NSAVP数据集和基准

时间： 2024-01-27T10:40:46.045+0800

19、 题目： A Survey on Autonomous Driving Datasets: Data Statistic, Annotation, and Outlook

链接：https://t.zsxq.com/HZCx9

简介： 200+自动驾驶数据集全面调研！

时间： 2024-01-04T22:54:54.556+0800

20、 题目：英伟达和卡内基梅隆大学最新！V2V-LLM：基于多模态大语言模型的车对车协作式自动驾驶

链接：https://t.zsxq.com/07jyx

简介： 一种基于LLM的协作式自动驾驶新框架，并配套发布首个面向车对车问答（V2V-QA）的数据集与评测基准

https://mp.weixin.qq.com/s/gBmrPWyK77wUzsftx2Tw9w


https://mp.weixin.qq.com/s/IznY5Zpk_dhOk-oyx6Nnsg

谈谈DeepSeek对自动驾驶的影响




https://drive-bench.github.io/ Are VLMs Ready for Autonomous Driving?
An Empirical Study from the Reliability, Data, and Metric Perspectives