<!DOCTYPE html><!--Wshr4sca6vnMpI1n_b5nc--><html lang="en" class="scroll-smooth"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/2c656e796d40db71.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-32b99883bf220ffe.js"/><script src="/_next/static/chunks/4bd1b696-c023c6e3521b1417.js" async=""></script><script src="/_next/static/chunks/255-e057be79bd379a49.js" async=""></script><script src="/_next/static/chunks/main-app-0848fe8fcd7d3e33.js" async=""></script><script src="/_next/static/chunks/185-02e5984e85404956.js" async=""></script><script src="/_next/static/chunks/619-9168df9c2a29b74b.js" async=""></script><script src="/_next/static/chunks/599-36b43173d762fc47.js" async=""></script><script src="/_next/static/chunks/app/layout-fbbcddd6b0817a6b.js" async=""></script><script src="/_next/static/chunks/140-a12817f2f4d4a964.js" async=""></script><script src="/_next/static/chunks/681-395f57ca35f99fd4.js" async=""></script><script src="/_next/static/chunks/app/%5Bslug%5D/page-fcd0e1bff3b87e28.js" async=""></script><link rel="icon" href="/DALL.svg" type="image/svg+xml"/><link rel="dns-prefetch" href="https://google-fonts.jialeliu.com"/><link rel="preconnect" href="https://google-fonts.jialeliu.com" crossorigin=""/><link rel="preload" as="style" href="https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&amp;family=Crimson+Text:ital,wght@0,400;0,600;1,400&amp;display=swap"/><title>Publications | Mo Mengjingcheng</title><meta name="description" content="A collection of my research work."/><meta name="author" content="Mo Mengjingcheng (èŽ«æ¢¦ç«Ÿæˆ)"/><meta name="keywords" content="Mo Mengjingcheng (èŽ«æ¢¦ç«Ÿæˆ),PhD,Research,Chongqing University of Posts and Telecommunications"/><meta name="creator" content="Mo Mengjingcheng (èŽ«æ¢¦ç«Ÿæˆ)"/><meta name="publisher" content="Mo Mengjingcheng (èŽ«æ¢¦ç«Ÿæˆ)"/><meta property="og:title" content="Mo Mengjingcheng"/><meta property="og:description" content="PhD student at Chongqing University of Posts and Telecommunications focusing on video anomaly understanding and embodied intelligence."/><meta property="og:site_name" content="Mo Mengjingcheng (èŽ«æ¢¦ç«Ÿæˆ)&#x27;s Academic Website"/><meta property="og:locale" content="en_US"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Mo Mengjingcheng"/><meta name="twitter:description" content="PhD student at Chongqing University of Posts and Telecommunications focusing on video anomaly understanding and embodied intelligence."/><link rel="icon" href="/DALL.svg"/><link rel="stylesheet" id="gfonts-css" href="https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&amp;family=Crimson+Text:ital,wght@0,400;0,600;1,400&amp;display=swap" media="print"/><script>
              (function(){
                var l = document.getElementById('gfonts-css');
                if (!l) return;
                if (l.media !== 'all') {
                  l.addEventListener('load', function(){ try { l.media = 'all'; } catch(e){} });
                }
              })();
            </script><noscript><link rel="stylesheet" href="https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&amp;family=Crimson+Text:ital,wght@0,400;0,600;1,400&amp;display=swap"/></noscript><script>
              try {
                const theme = localStorage.getItem('theme-storage');
                const parsed = theme ? JSON.parse(theme) : null;
                const setting = parsed?.state?.theme || 'system';
                const prefersDark = typeof window !== 'undefined' && window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));
                var root = document.documentElement;
                root.classList.add(effective);
                root.setAttribute('data-theme', effective);
              } catch (e) {
                var root = document.documentElement;
                root.classList.add('light');
                root.setAttribute('data-theme', 'light');
              }
            </script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="font-sans antialiased"><div hidden=""><!--$--><!--/$--></div><div style="visibility:hidden"><nav class="fixed top-0 left-0 right-0 z-50" data-headlessui-state=""><div class="transition-all duration-300 ease-out bg-transparent" style="transform:translateY(-100px)"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between items-center h-16 lg:h-20"><div class="flex-shrink-0" tabindex="0"><a class="text-xl lg:text-2xl font-serif font-semibold text-primary hover:text-accent transition-colors duration-200" href="/">Mo Mengjingcheng</a></div><div class="hidden lg:block"><div class="ml-10 flex items-center space-x-8"><div class="flex items-baseline space-x-8"><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/"><span class="relative z-10">About</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-primary" href="/publications/"><span class="relative z-10">Publications</span><div class="absolute inset-0 bg-accent/10 rounded-lg"></div></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/teaching/"><span class="relative z-10">Teaching</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/awards/"><span class="relative z-10">Awards</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/services/"><span class="relative z-10">Services</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/cv/"><span class="relative z-10">CV</span></a></div><div class="flex items-center justify-center w-10 h-10 rounded-lg border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] bg-background dark:bg-neutral-800"><div class="w-4 h-4 rounded-full bg-neutral-300 animate-pulse"></div></div></div></div><div class="lg:hidden flex items-center space-x-2"><div class="flex items-center justify-center w-10 h-10 rounded-lg border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] bg-background dark:bg-neutral-800"><div class="w-4 h-4 rounded-full bg-neutral-300 animate-pulse"></div></div><button class="inline-flex items-center justify-center p-2 rounded-md text-neutral-600 hover:text-primary hover:bg-neutral-100 dark:hover:bg-neutral-800 focus:outline-none focus:ring-2 focus:ring-inset focus:ring-accent transition-colors duration-200" id="headlessui-disclosure-button-_R_5pdb_" type="button" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Open main menu</span><div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="block h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></div></button></div></div></div></div></nav><main class="min-h-screen pt-16 lg:pt-20"><div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-12"><div style="opacity:0;transform:translateY(20px)"><div class="mb-8"><h1 class="text-4xl font-serif font-bold text-primary mb-4">Publications</h1><p class="text-lg text-neutral-600 dark:text-neutral-500 max-w-2xl">A collection of my research work.</p></div><div class="mb-8 space-y-4"><div class="flex flex-col sm:flex-row gap-4"><div class="relative flex-grow"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="absolute left-3 top-1/2 transform -translate-y-1/2 h-5 w-5 text-neutral-400"><path stroke-linecap="round" stroke-linejoin="round" d="m21 21-5.197-5.197m0 0A7.5 7.5 0 1 0 5.196 5.196a7.5 7.5 0 0 0 10.607 10.607Z"></path></svg><input type="text" placeholder="Search publications..." class="w-full pl-10 pr-4 py-2 rounded-lg border border-neutral-200 dark:border-neutral-800 bg-white dark:bg-neutral-900 focus:ring-2 focus:ring-accent focus:border-transparent transition-all duration-200" value=""/></div><button class="flex items-center justify-center px-4 py-2 rounded-lg border transition-all duration-200 bg-white dark:bg-neutral-900 border-neutral-200 dark:border-neutral-800 text-neutral-600 hover:border-accent hover:text-accent"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-5 w-5 mr-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3c2.755 0 5.455.232 8.083.678.533.09.917.556.917 1.096v1.044a2.25 2.25 0 0 1-.659 1.591l-5.432 5.432a2.25 2.25 0 0 0-.659 1.591v2.927a2.25 2.25 0 0 1-1.244 2.013L9.75 21v-6.568a2.25 2.25 0 0 0-.659-1.591L3.659 7.409A2.25 2.25 0 0 1 3 5.818V4.774c0-.54.384-1.006.917-1.096A48.32 48.32 0 0 1 12 3Z"></path></svg>Filters</button></div></div><div class="space-y-6"><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">BeVLM: GoT-Based Integration of BEV and LLM for Driving with Language</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="">Yang Dong</span>, </span><span><span class="">Hansheng Liang</span>, </span><span><span class="">Mingliang Zhai</span>, </span><span><span class="">Cheng Li</span>, </span><span><span class="">Meng Xia</span>, </span><span><span class="">Xinglin Liu</span>, </span><span><span class="font-semibold text-accent">Mengjingcheng Mo</span>, </span><span><span class="">Jiaxu Leng</span>, </span><span><span class="">Ji Tao</span>, </span><span><span class="">Xinbo Gao</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3"> <!-- -->2026</p><div class="flex flex-wrap gap-2 mt-auto"><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="w-full md:w-48 flex-shrink-0"><div class="aspect-video md:aspect-[4/3] relative rounded-lg overflow-hidden bg-neutral-100 dark:bg-neutral-800"><img alt="A2Seek: Towards Reasoning-Centric Benchmark for Aerial Anomaly Understanding" loading="lazy" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/papers/cover-a2seek.png"/></div></div><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">A2Seek: Towards Reasoning-Centric Benchmark for Aerial Anomaly Understanding</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="font-semibold text-accent">Mengjingcheng Mo</span>, </span><span><span class="">Xinyang Tong</span>, </span><span><span class="">Mingpi Tan</span>, </span><span><span class="">Jiaxu Leng</span><sup class="ml-0 text-neutral-600 dark:text-neutral-400">*</sup>, </span><span><span class="">Jiankang Zheng</span>, </span><span><span class="">Yiran Liu</span>, </span><span><span class="">Haosheng Chen</span>, </span><span><span class="">Ji Gan</span>, </span><span><span class="">Weisheng Li</span>, </span><span><span class="">Xinbo Gao</span><sup class="ml-0 text-neutral-600 dark:text-neutral-400">*</sup></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">arXiv preprint arXiv:2505.21962<!-- --> <!-- -->2025</p><div class="flex flex-wrap gap-2 mt-auto"><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">Shape-Centered Representation Learning for Visible-Infrared Person Re-Identification</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="">Shuang Li</span>, </span><span><span class="">Jiaxu Leng</span>, </span><span><span class="">Ji Gan</span>, </span><span><span class="font-semibold text-accent">Mengjingcheng Mo</span>, </span><span><span class="">Xinbo Gao</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">Pattern Recognition<!-- --> <!-- -->2025</p><div class="flex flex-wrap gap-2 mt-auto"><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for Hybrid Event Stream Perception</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="">Haosheng Chen</span>, </span><span><span class="">Lian Luo</span>, </span><span><span class="font-semibold text-accent">Mengjingcheng Mo</span>, </span><span><span class="">Zhanjie Wu</span>, </span><span><span class="">Guobao Xiao</span>, </span><span><span class="">Ji Gan</span>, </span><span><span class="">Jiaxu Leng</span>, </span><span><span class="">Xinbo Gao</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">arXiv preprint arXiv:2504.16616<!-- --> <!-- -->2025</p><div class="flex flex-wrap gap-2 mt-auto"><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">PiercingEye: Dual-Space Video Violence Detection with Hyperbolic Vision-Language Guidance</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="">Jiaxu Leng</span>, </span><span><span class="">Zhanjie Wu</span>, </span><span><span class="">Mingpi Tan</span>, </span><span><span class="font-semibold text-accent">Mengjingcheng Mo</span>, </span><span><span class="">Jiankang Zheng</span>, </span><span><span class="">Qingqing Li</span>, </span><span><span class="">Ji Gan</span>, </span><span><span class="">Xinbo Gao</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">arXiv preprint arXiv:2504.18866<!-- --> <!-- -->2025</p><div class="flex flex-wrap gap-2 mt-auto"><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">NexusAD: Exploring the Nexus for Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="font-semibold text-accent">Mengjingcheng Mo</span>, </span><span><span class="">Jingxin Wang</span>, </span><span><span class="">Like Wang</span>, </span><span><span class="">Haosheng Chen</span>, </span><span><span class="">Changjun Gu</span>, </span><span><span class="">Jiaxu Leng</span>, </span><span><span class="">Xinbo Gao</span><sup class="ml-0 text-neutral-600 dark:text-neutral-400">*</sup></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">ECCV 2024 Workshop on Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving<!-- --> <!-- -->2024</p><div class="flex flex-wrap gap-2 mt-auto"><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">Difficulty-Guided Variant Degradation Learning for Blind Image Super-Resolution</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="">Jiaxu Leng</span>, </span><span><span class="">Jia Wang</span>, </span><span><span class="font-semibold text-accent">Mengjingcheng Mo</span>, </span><span><span class="">Ji Gan</span>, </span><span><span class="">Wen Lu</span>, </span><span><span class="">Xinbo Gao</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">IEEE Transactions on Neural Networks and Learning Systems<!-- --> <!-- -->2024</p><div class="flex flex-wrap gap-2 mt-auto"><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">Recent Advances for Aerial Object Detection: A Survey</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="">Jiaxu Leng</span>, </span><span><span class="">Yongming Ye</span>, </span><span><span class="font-semibold text-accent">Mengjingcheng Moâ€ </span>, </span><span><span class="">Chenqiang Gao</span>, </span><span><span class="">Ji Gan</span>, </span><span><span class="">Bin Xiao</span>, </span><span><span class="">Xinbo Gao</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">ACM Computing Surveys<!-- --> <!-- -->2024</p><div class="flex flex-wrap gap-2 mt-auto"><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">Dual Space Embedding Learning for Weakly Supervised Audio-Visual Violence Detection</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="">Yiran Liu</span>, </span><span><span class="">Zhanjie Wu</span>, </span><span><span class="font-semibold text-accent">Mengjingcheng Mo</span>, </span><span><span class="">Ji Gan</span>, </span><span><span class="">Jiaxu Leng</span>, </span><span><span class="">Xinbo Gao</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">2024 IEEE International Conference on Multimedia and Expo (ICME)<!-- --> <!-- -->2024</p><div class="flex flex-wrap gap-2 mt-auto"><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">Where to Look: Multi-Granularity Occlusion-Aware for Video Person Re-Identification</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="">Jiaxu Leng</span>, </span><span><span class="">Haitao Wang</span>, </span><span><span class="">Xinbo Gao</span>, </span><span><span class="">Yan Zhang</span>, </span><span><span class="">Ye Wang</span>, </span><span><span class="font-semibold text-accent">Mengjingcheng Mo</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">Neurocomputing<!-- --> <!-- -->2023</p><div class="flex flex-wrap gap-2 mt-auto"><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">Atomic Number Prior Guided Network for Prohibited Items Detection from Heavily Cluttered X-Ray Imagery</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="">Jinwen Chen</span>, </span><span><span class="">Jiaxu Leng</span>, </span><span><span class="">Xinbo Gao</span>, </span><span><span class="font-semibold text-accent">Mengjingcheng Mo</span>, </span><span><span class="">Shibo Guan</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">Frontiers in Physics<!-- --> <!-- -->2023</p><div class="flex flex-wrap gap-2 mt-auto"><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">Pareto Refocusing for Drone-View Object Detection</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="">Jiaxu Leng</span>, </span><span><span class="font-semibold text-accent">Mengjingcheng Mo</span>, </span><span><span class="">Yinghua Zhou</span>, </span><span><span class="">Chenqiang Gao</span>, </span><span><span class="">Weisheng Li</span>, </span><span><span class="">Xinbo Gao</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">IEEE Transactions on Circuits and Systems for Video Technology<!-- --> <!-- -->2022</p><div class="flex flex-wrap gap-2 mt-auto"><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">Sampling-Invariant Fully Metric Learning for Few-Shot Object Detection</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="">Jiaxu Leng</span>, </span><span><span class="">Taiyue Chen</span>, </span><span><span class="">Xinbo Gao</span>, </span><span><span class="font-semibold text-accent">Mengjingcheng Mo</span>, </span><span><span class="">Yongtao Yu</span>, </span><span><span class="">Yan Zhang</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">Neurocomputing<!-- --> <!-- -->2022</p><div class="flex flex-wrap gap-2 mt-auto"><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div><div class="bg-white dark:bg-neutral-900 p-6 rounded-xl shadow-sm border border-neutral-200 dark:border-neutral-800 hover:shadow-md transition-all duration-200" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col md:flex-row gap-6"><div class="flex-grow"><h3 class="text-xl font-semibold text-primary mb-2 leading-tight">Recent Advances in Small Object Detection</h3><p class="text-base text-neutral-600 dark:text-neutral-400 mb-2"><span><span class="">Xinbo Gao</span>, </span><span><span class="font-semibold text-accent">Mengjingcheng Mo</span>, </span><span><span class="">Haitao Wang</span>, </span><span><span class="">Jiaxu Leng</span></span></p><p class="text-sm font-medium text-neutral-800 dark:text-neutral-600 mb-3">Journal of Data Acquisition and Processing<!-- --> <!-- -->2021</p><div class="flex flex-wrap gap-2 mt-auto"><button class="inline-flex items-center px-3 py-1 rounded-md text-xs font-medium transition-colors bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-300 hover:bg-accent hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-3 w-3 mr-1.5"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25"></path></svg>BibTeX</button></div></div></div></div></div></div></div><!--$--><!--/$--></main><footer class="border-t border-neutral-200/50 bg-neutral-50/50 dark:bg-neutral-900/50 dark:border-neutral-700/50"><div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-6"><div class="flex flex-col sm:flex-row justify-between items-center gap-2"><p class="text-xs text-neutral-500">Last updated: <!-- -->February 3, 2026</p><p class="text-xs text-neutral-500 flex items-center"><a href="https://github.com/xyjoey/PRISM" target="_blank" rel="noopener noreferrer">Built with PRISM</a><span class="ml-2">ðŸš€</span></p></div></div></footer></div><script src="/_next/static/chunks/webpack-32b99883bf220ffe.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7558,[\"185\",\"static/chunks/185-02e5984e85404956.js\",\"619\",\"static/chunks/619-9168df9c2a29b74b.js\",\"599\",\"static/chunks/599-36b43173d762fc47.js\",\"177\",\"static/chunks/app/layout-fbbcddd6b0817a6b.js\"],\"ThemeProvider\"]\n3:I[9994,[\"185\",\"static/chunks/185-02e5984e85404956.js\",\"619\",\"static/chunks/619-9168df9c2a29b74b.js\",\"599\",\"static/chunks/599-36b43173d762fc47.js\",\"177\",\"static/chunks/app/layout-fbbcddd6b0817a6b.js\"],\"default\"]\n4:I[9766,[],\"\"]\n5:I[8924,[],\"\"]\nc:I[7150,[],\"\"]\n:HL[\"/_next/static/css/2c656e796d40db71.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"Wshr4sca6vnMpI1n_b5nc\",\"p\":\"\",\"c\":[\"\",\"publications\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[[\"slug\",\"publications\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/2c656e796d40db71.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"scroll-smooth\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/DALL.svg\",\"type\":\"image/svg+xml\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://google-fonts.jialeliu.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://google-fonts.jialeliu.com\",\"crossOrigin\":\"\"}],[\"$\",\"link\",null,{\"rel\":\"preload\",\"as\":\"style\",\"href\":\"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700\u0026family=Crimson+Text:ital,wght@0,400;0,600;1,400\u0026display=swap\"}],[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"id\":\"gfonts-css\",\"href\":\"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700\u0026family=Crimson+Text:ital,wght@0,400;0,600;1,400\u0026display=swap\",\"media\":\"print\"}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              (function(){\\n                var l = document.getElementById('gfonts-css');\\n                if (!l) return;\\n                if (l.media !== 'all') {\\n                  l.addEventListener('load', function(){ try { l.media = 'all'; } catch(e){} });\\n                }\\n              })();\\n            \"}}],[\"$\",\"noscript\",null,{\"children\":[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"href\":\"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700\u0026family=Crimson+Text:ital,wght@0,400;0,600;1,400\u0026display=swap\"}]}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              try {\\n                const theme = localStorage.getItem('theme-storage');\\n                const parsed = theme ? JSON.parse(theme) : null;\\n                const setting = parsed?.state?.theme || 'system';\\n                const prefersDark = typeof window !== 'undefined' \u0026\u0026 window.matchMedia \u0026\u0026 window.matchMedia('(prefers-color-scheme: dark)').matches;\\n                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));\\n                var root = document.documentElement;\\n                root.classList.add(effective);\\n                root.setAttribute('data-theme', effective);\\n              } catch (e) {\\n                var root = document.documentElement;\\n                root.classList.add('light');\\n                root.setAttribute('data-theme', 'light');\\n              }\\n            \"}}]]}],[\"$\",\"body\",null,{\"className\":\"font-sans antialiased\",\"children\":[\"$\",\"$L2\",null,{\"children\":[[\"$\",\"$L3\",null,{\"items\":[{\"title\":\"About\",\"type\":\"page\",\"target\":\"about\",\"href\":\"/\"},{\"title\":\"Publications\",\"type\":\"page\",\"target\":\"publications\",\"href\":\"/publications\"},{\"title\":\"Teaching\",\"type\":\"page\",\"target\":\"teaching\",\"href\":\"/teaching\"},{\"title\":\"Awards\",\"type\":\"page\",\"target\":\"awards\",\"href\":\"/awards\"},{\"title\":\"Services\",\"type\":\"page\",\"target\":\"services\",\"href\":\"/services\"},{\"title\":\"CV\",\"type\":\"page\",\"target\":\"cv\",\"href\":\"/cv\"}],\"siteTitle\":\"Mo Mengjingcheng\",\"enableOnePageMode\":false}],[\"$\",\"main\",null,{\"className\":\"min-h-screen pt-16 lg:pt-20\",\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],\"$L6\",\"$L7\"]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],\"$L8\"]}]}]]}]]}],{\"children\":[[\"slug\",\"publications\",\"d\"],\"$L9\",{\"children\":[\"__PAGE__\",\"$La\",{},null,false]},null,false]},null,false],\"$Lb\",false]],\"m\":\"$undefined\",\"G\":[\"$c\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"d:I[7923,[\"185\",\"static/chunks/185-02e5984e85404956.js\",\"619\",\"static/chunks/619-9168df9c2a29b74b.js\",\"599\",\"static/chunks/599-36b43173d762fc47.js\",\"177\",\"static/chunks/app/layout-fbbcddd6b0817a6b.js\"],\"default\"]\nf:I[4431,[],\"OutletBoundary\"]\n11:I[5278,[],\"AsyncMetadataOutlet\"]\n13:I[4431,[],\"ViewportBoundary\"]\n15:I[4431,[],\"MetadataBoundary\"]\n16:\"$Sreact.suspense\"\n6:[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}]\n7:[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]\n8:[\"$\",\"$Ld\",null,{\"lastUpdated\":\"February 3, 2026\"}]\n9:[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}]\na:[\"$\",\"$1\",\"c\",{\"children\":[\"$Le\",null,[\"$\",\"$Lf\",null,{\"children\":[\"$L10\",[\"$\",\"$L11\",null,{\"promise\":\"$@12\"}]]}]]}]\nb:[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L13\",null,{\"children\":\"$L14\"}],null],[\"$\",\"$L15\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$16\",null,{\"fallback\":null,\"children\":\"$L17\"}]}]}]]}]\n"])</script><script>self.__next_f.push([1,"18:I[9958,[\"185\",\"static/chunks/185-02e5984e85404956.js\",\"140\",\"static/chunks/140-a12817f2f4d4a964.js\",\"681\",\"static/chunks/681-395f57ca35f99fd4.js\",\"182\",\"static/chunks/app/%5Bslug%5D/page-fcd0e1bff3b87e28.js\"],\"default\"]\n"])</script><script>self.__next_f.push([1,"e:[\"$\",\"div\",null,{\"className\":\"max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-12\",\"children\":[[\"$\",\"$L18\",null,{\"config\":{\"type\":\"publication\",\"title\":\"Publications\",\"description\":\"A collection of my research work.\",\"source\":\"publications.bib\"},\"publications\":[{\"id\":\"dongbevlm\",\"title\":\"BeVLM: GoT-Based Integration of BEV and LLM for Driving with Language\",\"authors\":[{\"name\":\"Yang Dong\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Hansheng Liang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Mingliang Zhai\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Cheng Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Meng Xia\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinglin Liu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Mengjingcheng Mo\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jiaxu Leng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ji Tao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinbo Gao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2026,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$e:props:children:0:props:publications:0:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"\",\"conference\":\"\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"bibtex\":\"@article{dongbevlm,\\n  title = {BeVLM: GoT-Based Integration of BEV and LLM for Driving with Language},\\n  author = {Dong, Yang and Liang, Hansheng and Zhai, Mingliang and Li, Cheng and Xia, Meng and Liu, Xinglin and Mo, Mengjingcheng and Leng, Jiaxu and Tao, Ji and Gao, Xinbo}\\n}\"},{\"id\":\"mo2025a2seek\",\"title\":\"A2Seek: Towards Reasoning-Centric Benchmark for Aerial Anomaly Understanding\",\"authors\":[{\"name\":\"Mengjingcheng Mo\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinyang Tong\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Mingpi Tan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jiaxu Leng\",\"isHighlighted\":false,\"isCorresponding\":true,\"isCoAuthor\":false},{\"name\":\"Jiankang Zheng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yiran Liu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Haosheng Chen\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ji Gan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Weisheng Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinbo Gao\",\"isHighlighted\":false,\"isCorresponding\":true,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$e:props:children:0:props:publications:1:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"arXiv preprint arXiv:2505.21962\",\"conference\":\"\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"cover-a2seek.png\",\"bibtex\":\"@article{mo2025a2seek,\\n  title = {A2Seek: Towards Reasoning-Centric Benchmark for Aerial Anomaly Understanding},\\n  author = {Mo, Mengjingcheng and Tong, Xinyang and Tan, Mingpi and Leng, Jiaxu and Zheng, Jiankang and Liu, Yiran and Chen, Haosheng and Gan, Ji and Li, Weisheng and Gao, Xinbo},\\n  journal = {arXiv preprint arXiv:2505.21962},\\n  year = {2025}\\n}\"},{\"id\":\"li2025shape\",\"title\":\"Shape-Centered Representation Learning for Visible-Infrared Person Re-Identification\",\"authors\":[{\"name\":\"Shuang Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jiaxu Leng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ji Gan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Mengjingcheng Mo\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinbo Gao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$e:props:children:0:props:publications:2:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"Pattern Recognition\",\"conference\":\"\",\"pages\":\"111756\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"bibtex\":\"@article{li2025shape,\\n  title = {Shape-Centered Representation Learning for Visible-Infrared Person Re-Identification},\\n  author = {Li, Shuang and Leng, Jiaxu and Gan, Ji and Mo, Mengjingcheng and Gao, Xinbo},\\n  journal = {Pattern Recognition},\\n  pages = {111756},\\n  year = {2025},\\n  publisher = {Pergamon}\\n}\"},{\"id\":\"chen2025ehgcn\",\"title\":\"EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for Hybrid Event Stream Perception\",\"authors\":[{\"name\":\"Haosheng Chen\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Lian Luo\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Mengjingcheng Mo\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zhanjie Wu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Guobao Xiao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ji Gan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jiaxu Leng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinbo Gao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$e:props:children:0:props:publications:3:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"arXiv preprint arXiv:2504.16616\",\"conference\":\"\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"bibtex\":\"@article{chen2025ehgcn,\\n  title = {EHGCN: Hierarchical Euclidean-Hyperbolic Fusion via Motion-Aware GCN for Hybrid Event Stream Perception},\\n  author = {Chen, Haosheng and Luo, Lian and Mo, Mengjingcheng and Wu, Zhanjie and Xiao, Guobao and Gan, Ji and Leng, Jiaxu and Gao, Xinbo},\\n  journal = {arXiv preprint arXiv:2504.16616},\\n  year = {2025}\\n}\"},{\"id\":\"leng2025piercingeye\",\"title\":\"PiercingEye: Dual-Space Video Violence Detection with Hyperbolic Vision-Language Guidance\",\"authors\":[{\"name\":\"Jiaxu Leng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zhanjie Wu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Mingpi Tan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Mengjingcheng Mo\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jiankang Zheng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Qingqing Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ji Gan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinbo Gao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$e:props:children:0:props:publications:4:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"arXiv preprint arXiv:2504.18866\",\"conference\":\"\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"bibtex\":\"@article{leng2025piercingeye,\\n  title = {PiercingEye: Dual-Space Video Violence Detection with Hyperbolic Vision-Language Guidance},\\n  author = {Leng, Jiaxu and Wu, Zhanjie and Tan, Mingpi and Mo, Mengjingcheng and Zheng, Jiankang and Li, Qingqing and Gan, Ji and Gao, Xinbo},\\n  journal = {arXiv preprint arXiv:2504.18866},\\n  year = {2025}\\n}\"},{\"id\":\"mo2024nexusad\",\"title\":\"NexusAD: Exploring the Nexus for Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving\",\"authors\":[{\"name\":\"Mengjingcheng Mo\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jingxin Wang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Like Wang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Haosheng Chen\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Changjun Gu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jiaxu Leng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinbo Gao\",\"isHighlighted\":false,\"isCorresponding\":true,\"isCoAuthor\":false}],\"year\":2024,\"type\":\"conference\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$e:props:children:0:props:publications:5:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"\",\"conference\":\"ECCV 2024 Workshop on Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"bibtex\":\"@inproceedings{mo2024nexusad,\\n  title = {NexusAD: Exploring the Nexus for Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving},\\n  author = {Mo, Mengjingcheng and Wang, Jingxin and Wang, Like and Chen, Haosheng and Gu, Changjun and Leng, Jiaxu and Gao, Xinbo},\\n  booktitle = {ECCV 2024 Workshop on Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving},\\n  year = {2024}\\n}\"},{\"id\":\"leng2024difficulty\",\"title\":\"Difficulty-Guided Variant Degradation Learning for Blind Image Super-Resolution\",\"authors\":[{\"name\":\"Jiaxu Leng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jia Wang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Mengjingcheng Mo\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ji Gan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wen Lu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinbo Gao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2024,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$e:props:children:0:props:publications:6:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"conference\":\"\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"bibtex\":\"@article{leng2024difficulty,\\n  title = {Difficulty-Guided Variant Degradation Learning for Blind Image Super-Resolution},\\n  author = {Leng, Jiaxu and Wang, Jia and Mo, Mengjingcheng and Gan, Ji and Lu, Wen and Gao, Xinbo},\\n  journal = {IEEE Transactions on Neural Networks and Learning Systems},\\n  year = {2024},\\n  publisher = {IEEE}\\n}\"},{\"id\":\"leng2024recent\",\"title\":\"Recent Advances for Aerial Object Detection: A Survey\",\"authors\":[{\"name\":\"Jiaxu Leng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yongming Ye\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Mengjingcheng Moâ€ \",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Chenqiang Gao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ji Gan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Bin Xiao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinbo Gao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2024,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$e:props:children:0:props:publications:7:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"ACM Computing Surveys\",\"conference\":\"\",\"volume\":\"56\",\"issue\":\"12\",\"pages\":\"1--36\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"bibtex\":\"@article{leng2024recent,\\n  title = {Recent Advances for Aerial Object Detection: A Survey},\\n  author = {Leng, Jiaxu and Ye, Yongming and Moâ€ , Mengjingcheng and Gao, Chenqiang and Gan, Ji and Xiao, Bin and Gao, Xinbo},\\n  journal = {ACM Computing Surveys},\\n  volume = {56},\\n  number = {12},\\n  pages = {1--36},\\n  year = {2024},\\n  publisher = {ACM}\\n}\"},{\"id\":\"liu2024dual\",\"title\":\"Dual Space Embedding Learning for Weakly Supervised Audio-Visual Violence Detection\",\"authors\":[{\"name\":\"Yiran Liu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zhanjie Wu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Mengjingcheng Mo\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ji Gan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jiaxu Leng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinbo Gao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2024,\"type\":\"conference\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$e:props:children:0:props:publications:8:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"\",\"conference\":\"2024 IEEE International Conference on Multimedia and Expo (ICME)\",\"pages\":\"1--6\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"bibtex\":\"@inproceedings{liu2024dual,\\n  title = {Dual Space Embedding Learning for Weakly Supervised Audio-Visual Violence Detection},\\n  author = {Liu, Yiran and Wu, Zhanjie and Mo, Mengjingcheng and Gan, Ji and Leng, Jiaxu and Gao, Xinbo},\\n  booktitle = {2024 IEEE International Conference on Multimedia and Expo (ICME)},\\n  pages = {1--6},\\n  year = {2024},\\n  organization = {IEEE}\\n}\"},{\"id\":\"leng2023look\",\"title\":\"Where to Look: Multi-Granularity Occlusion-Aware for Video Person Re-Identification\",\"authors\":[{\"name\":\"Jiaxu Leng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Haitao Wang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinbo Gao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yan Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ye Wang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Mengjingcheng Mo\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2023,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$e:props:children:0:props:publications:9:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"Neurocomputing\",\"conference\":\"\",\"volume\":\"536\",\"pages\":\"137--151\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"bibtex\":\"@article{leng2023look,\\n  title = {Where to Look: Multi-Granularity Occlusion-Aware for Video Person Re-Identification},\\n  author = {Leng, Jiaxu and Wang, Haitao and Gao, Xinbo and Zhang, Yan and Wang, Ye and Mo, Mengjingcheng},\\n  journal = {Neurocomputing},\\n  volume = {536},\\n  pages = {137--151},\\n  year = {2023},\\n  publisher = {Elsevier}\\n}\"},{\"id\":\"chen2023atomic\",\"title\":\"Atomic Number Prior Guided Network for Prohibited Items Detection from Heavily Cluttered X-Ray Imagery\",\"authors\":[{\"name\":\"Jinwen Chen\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jiaxu Leng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinbo Gao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Mengjingcheng Mo\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shibo Guan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2023,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$e:props:children:0:props:publications:10:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"Frontiers in Physics\",\"conference\":\"\",\"volume\":\"10\",\"pages\":\"1117261\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"bibtex\":\"@article{chen2023atomic,\\n  title = {Atomic Number Prior Guided Network for Prohibited Items Detection from Heavily Cluttered X-Ray Imagery},\\n  author = {Chen, Jinwen and Leng, Jiaxu and Gao, Xinbo and Mo, Mengjingcheng and Guan, Shibo},\\n  journal = {Frontiers in Physics},\\n  volume = {10},\\n  pages = {1117261},\\n  year = {2023},\\n  publisher = {Frontiers Media SA}\\n}\"},{\"id\":\"leng2022pareto\",\"title\":\"Pareto Refocusing for Drone-View Object Detection\",\"authors\":[{\"name\":\"Jiaxu Leng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Mengjingcheng Mo\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yinghua Zhou\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Chenqiang Gao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Weisheng Li\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinbo Gao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2022,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$e:props:children:0:props:publications:11:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"conference\":\"\",\"volume\":\"33\",\"issue\":\"3\",\"pages\":\"1320--1334\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"bibtex\":\"@article{leng2022pareto,\\n  title = {Pareto Refocusing for Drone-View Object Detection},\\n  author = {Leng, Jiaxu and Mo, Mengjingcheng and Zhou, Yinghua and Gao, Chenqiang and Li, Weisheng and Gao, Xinbo},\\n  journal = {IEEE Transactions on Circuits and Systems for Video Technology},\\n  volume = {33},\\n  number = {3},\\n  pages = {1320--1334},\\n  year = {2022},\\n  publisher = {IEEE}\\n}\"},{\"id\":\"leng2022sampling\",\"title\":\"Sampling-Invariant Fully Metric Learning for Few-Shot Object Detection\",\"authors\":[{\"name\":\"Jiaxu Leng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Taiyue Chen\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinbo Gao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Mengjingcheng Mo\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yongtao Yu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yan Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2022,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$e:props:children:0:props:publications:12:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"Neurocomputing\",\"conference\":\"\",\"volume\":\"511\",\"pages\":\"54--66\",\"abstract\":\"\",\"description\":\"\",\"selected\":false,\"bibtex\":\"@article{leng2022sampling,\\n  title = {Sampling-Invariant Fully Metric Learning for Few-Shot Object Detection},\\n  author = {Leng, Jiaxu and Chen, Taiyue and Gao, Xinbo and Mo, Mengjingcheng and Yu, Yongtao and Zhang, Yan},\\n  journal = {Neurocomputing},\\n  volume = {511},\\n  pages = {54--66},\\n  year = {2022},\\n  publisher = {Elsevier}\\n}\"},{\"id\":\"gao2021recent\",\"title\":\"Recent Advances in Small Object Detection\",\"authors\":[{\"name\":\"Xinbo Gao\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Mengjingcheng Mo\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Haitao Wang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jiaxu Leng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2021,\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$e:props:children:0:props:publications:13:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"Journal of Data Acquisition and Processing\",\"conference\":\"\",\"volume\":\"36\",\"issue\":\"3\",\"pages\":\"391--417\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"bibtex\":\"@article{gao2021recent,\\n  title = {Recent Advances in Small Object Detection},\\n  author = {Gao, Xinbo and Mo, Mengjingcheng and Wang, Haitao and Leng, Jiaxu},\\n  journal = {Journal of Data Acquisition and Processing},\\n  volume = {36},\\n  number = {3},\\n  pages = {391--417},\\n  year = {2021}\\n}\"}]}],false,false]}]\n"])</script><script>self.__next_f.push([1,"14:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n10:null\n"])</script><script>self.__next_f.push([1,"19:I[622,[],\"IconMark\"]\n"])</script><script>self.__next_f.push([1,"12:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Publications | Mo Mengjingcheng\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"A collection of my research work.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"author\",\"content\":\"Mo Mengjingcheng (èŽ«æ¢¦ç«Ÿæˆ)\"}],[\"$\",\"meta\",\"3\",{\"name\":\"keywords\",\"content\":\"Mo Mengjingcheng (èŽ«æ¢¦ç«Ÿæˆ),PhD,Research,Chongqing University of Posts and Telecommunications\"}],[\"$\",\"meta\",\"4\",{\"name\":\"creator\",\"content\":\"Mo Mengjingcheng (èŽ«æ¢¦ç«Ÿæˆ)\"}],[\"$\",\"meta\",\"5\",{\"name\":\"publisher\",\"content\":\"Mo Mengjingcheng (èŽ«æ¢¦ç«Ÿæˆ)\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:title\",\"content\":\"Mo Mengjingcheng\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:description\",\"content\":\"PhD student at Chongqing University of Posts and Telecommunications focusing on video anomaly understanding and embodied intelligence.\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:site_name\",\"content\":\"Mo Mengjingcheng (èŽ«æ¢¦ç«Ÿæˆ)'s Academic Website\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:title\",\"content\":\"Mo Mengjingcheng\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:description\",\"content\":\"PhD student at Chongqing University of Posts and Telecommunications focusing on video anomaly understanding and embodied intelligence.\"}],[\"$\",\"link\",\"14\",{\"rel\":\"icon\",\"href\":\"/DALL.svg\"}],[\"$\",\"$L19\",\"15\",{}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"17:\"$12:metadata\"\n"])</script></body></html>